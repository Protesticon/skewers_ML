{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from data_loader import *\n",
    "from model import *\n",
    "from test import *\n",
    "\n",
    "\n",
    "# pre-process\n",
    "def pre_proc(tau, block):\n",
    "    '''log(tau), 95%'''\n",
    "    tau_sum = tau.sum(axis=(-1,-2,-3))\n",
    "    limit = np.percentile(tau_sum, 95)\n",
    "    bln = np.ones(len(tau), 'bool')#tau_sum <= limit\n",
    "    tau = np.log(tau)\n",
    "    return (tau[bln],  block[bln])\n",
    "\n",
    "def toF_proc(tau):\n",
    "    '''transfer data derived from pre_proc to F=exp(-tau)'''\n",
    "    tau = np.exp(-np.exp(tau))\n",
    "    return tau\n",
    "\n",
    "def load_FGPA(FGPA, train_ousize, DM_param):\n",
    "    nx, ny, nz = (DM_param.pix / train_ousize).astype('int')\n",
    "    FGPA = FGPA.reshape(nx, train_ousize[0], ny, train_ousize[1], DM_param.pix)\\\n",
    "        .transpose(0, 2, 1, 3, 4).reshape(-1, train_ousize[0], train_ousize[1], DM_param.pix)\n",
    "\n",
    "    x = (np.arange(nx)*(train_ousize[0]) + (train_ousize[0]-1)/2)\n",
    "    y = (np.arange(ny)*(train_ousize[1]) + (train_ousize[1]-1)/2)\n",
    "    z = (np.arange(nz)*(train_ousize[2]) + (train_ousize[2]-1)/2)\n",
    "    \n",
    "    cx = x.repeat(ny*nz).reshape(nx,ny,nz).transpose(0,1,2).flatten()\n",
    "    cy = y.repeat(nz*nx).reshape(ny,nz,nx).transpose(2,0,1).flatten()\n",
    "    cz = z.repeat(nx*ny).reshape(nz,nx,ny).transpose(1,2,0).flatten()\n",
    "    block = np.array([cx, cy, cz]).T.reshape(-1, nz, 3)\n",
    "\n",
    "    return FGPA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Path and data file name\n",
    "folder  = Path.cwd().parent / 'Illustris1'\n",
    "DM_name = ['deltaDM_Illustris1_L75_N600_v2.fits', \n",
    "            'vx_DM_Illustris1_L75_N600.fits',\n",
    "            'vy_DM_Illustris1_L75_N600.fits',\n",
    "            'vz_DM_Illustris1_L75_N600.fits']\n",
    "ske_name = 'spectra_Illustris1_N600_xaxis.npy'\n",
    "FGPA_name = 'tau_normed_FGPA_smooth250kpc_therbr_RSD_Illustris-1_snap68_L75_N600_cic_xaxis.fits'\n",
    "\n",
    "\n",
    "\n",
    "# hyper parameters\n",
    "train_insize = np.array([11, 11, 141]) # x, y, z respctively\n",
    "train_ousize = np.array([1, 1, 75]) # x, y, z respctively\n",
    "test_batch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: Quadro P6000\n",
      "Loading dark matter...\n",
      "Loading skewers...\n",
      "Setting test set...\n"
     ]
    }
   ],
   "source": [
    "localtime_n = ['2020-12-24 23:42:28']\n",
    "localtime_i = localtime_n[0]\n",
    "localtime = time.strptime(localtime_i, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "# device used to train the model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using device:', torch.cuda.get_device_name(device=device.index))\n",
    "\n",
    "\n",
    "# load dark matter data\n",
    "print('Loading dark matter...')\n",
    "DM_general = load_DM(folder, DM_name)\n",
    "DM_general = DM_general.transpose(0,3,2,1)\n",
    "DM_general = DM_general[[0,3,2,1]]\n",
    "# basic paramters\n",
    "DM_param.pix  = len(DM_general[0])\n",
    "DM_param.len  = 75 # in Mpc/h\n",
    "DM_param.reso = DM_param.len / DM_param.pix # in Mpc/h\n",
    "# test\n",
    "if DM_general.shape[1]<train_insize.min():\n",
    "    raise ValueError('DarkMatter cube size',\n",
    "        DM_general.shape, 'is too small for train size', train_insize, '.')\n",
    "DM_general = torch.tensor(DM_general).float()\n",
    "\n",
    "\n",
    "# load skewers\n",
    "print('Loading skewers...')\n",
    "ske, block = load_skewers(folder, ske_name, train_ousize, DM_param)\n",
    "#ske_FGPA, block = load_skewers(folder, FGPA_name, train_ousize, DM_param)\n",
    "skeFGPA_file = fits.open(folder/FGPA_name)\n",
    "ske_FGPA = skeFGPA_file[0].data\n",
    "skeFGPA_file.close()\n",
    "ske_FGPA = ske_FGPA.transpose(2,1,0)\n",
    "ske_FGPA = load_FGPA(ske_FGPA, train_ousize, DM_param)\n",
    "# basic parameters\n",
    "ske_len = int(ske.shape[-1])\n",
    "\n",
    "\n",
    "# divide the sample to training, validation set, and test set.\n",
    "print('Setting test set...')\n",
    "'''\n",
    "with open(\"id_seperate/id_seperate_%s.txt\"\\\n",
    "          %time.strftime(\"%Y-%m-%d_%H:%M:%S\", localtime), \"r\") as f:\n",
    "    aa = f.readlines()\n",
    "    id_seperate = np.array(list(aa[0][::3])).astype('int')\n",
    "    del aa\n",
    "f.close()\n",
    "'''\n",
    "id_seperate = (np.concatenate((np.ones(36000), np.zeros(360000-36000)))*3).astype(int)\n",
    "np.random.shuffle(id_seperate)\n",
    "\n",
    "test_ske, test_block = load_test(ske, block, id_seperate,\n",
    "                                 train_ousize, test_batch, pre_proc)\n",
    "test_FGPA, test_block = load_test(ske_FGPA, block, id_seperate,\n",
    "                                 train_ousize, test_batch, pre_proc)\n",
    "del id_seperate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalization_outp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-34484a2dc3af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this parameter deviates the PDF of ML F and hydro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# why so large difference? maybe train on normalized skewers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnormalization_outp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalization_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'normalization_outp' is not defined"
     ]
    }
   ],
   "source": [
    "# this parameter deviates the PDF of ML F and hydro\n",
    "# why so large difference? maybe train on normalized skewers\n",
    "normalization_outp, normalization_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Begin testing...\n",
      "Step [ 100/5760] Loss: 0.4538, Time: 15.3213\n",
      "Step [ 200/5760] Loss: 0.8085, Time: 29.7587\n",
      "Step [ 300/5760] Loss: 0.4095, Time: 44.3660\n",
      "Step [ 400/5760] Loss: 0.4064, Time: 59.6752\n",
      "Step [ 500/5760] Loss: 0.4312, Time: 74.6661\n",
      "Step [ 600/5760] Loss: 0.6441, Time: 89.4831\n",
      "Step [ 700/5760] Loss: 0.4979, Time: 103.8671\n",
      "Step [ 800/5760] Loss: 0.3990, Time: 118.4493\n",
      "Step [ 900/5760] Loss: 0.6918, Time: 133.1607\n",
      "Step [1000/5760] Loss: 0.3418, Time: 148.1330\n",
      "Step [1100/5760] Loss: 0.4421, Time: 162.7147\n",
      "Step [1200/5760] Loss: 0.8133, Time: 177.1273\n",
      "Step [1300/5760] Loss: 0.3807, Time: 191.8581\n",
      "Step [1400/5760] Loss: 0.4278, Time: 206.2691\n",
      "Step [1500/5760] Loss: 0.8421, Time: 220.4819\n",
      "Step [1600/5760] Loss: 0.3761, Time: 234.6868\n",
      "Step [1700/5760] Loss: 0.4632, Time: 249.0502\n",
      "Step [1800/5760] Loss: 0.4292, Time: 263.5987\n",
      "Step [1900/5760] Loss: 0.6576, Time: 278.0924\n",
      "Step [2000/5760] Loss: 0.4193, Time: 292.5582\n",
      "Step [2100/5760] Loss: 0.5455, Time: 306.8702\n",
      "Step [2200/5760] Loss: 0.6331, Time: 321.1669\n",
      "Step [2300/5760] Loss: 0.5121, Time: 335.7276\n",
      "Step [2400/5760] Loss: 0.3978, Time: 349.8147\n",
      "Step [2500/5760] Loss: 0.4000, Time: 364.1244\n",
      "Step [2600/5760] Loss: 0.4249, Time: 378.3028\n",
      "Step [2700/5760] Loss: 0.4075, Time: 392.6904\n",
      "Step [2800/5760] Loss: 0.4982, Time: 406.9429\n",
      "Step [2900/5760] Loss: 0.5224, Time: 421.6181\n",
      "Step [3000/5760] Loss: 0.5732, Time: 435.9199\n",
      "Step [3100/5760] Loss: 0.4125, Time: 450.5555\n",
      "Step [3200/5760] Loss: 0.6985, Time: 465.3505\n",
      "Step [3300/5760] Loss: 0.4303, Time: 479.9374\n",
      "Step [3400/5760] Loss: 0.4964, Time: 493.8698\n",
      "Step [3500/5760] Loss: 0.4060, Time: 508.3005\n",
      "Step [3600/5760] Loss: 0.3929, Time: 522.8016\n",
      "Step [3700/5760] Loss: 0.4483, Time: 537.3896\n",
      "Step [3800/5760] Loss: 0.8683, Time: 551.7381\n",
      "Step [3900/5760] Loss: 0.4586, Time: 565.8836\n",
      "Step [4000/5760] Loss: 0.4848, Time: 579.8815\n",
      "Step [4100/5760] Loss: 0.9324, Time: 594.1783\n",
      "Step [4200/5760] Loss: 0.4516, Time: 608.5037\n",
      "Step [4300/5760] Loss: 0.5643, Time: 622.8410\n",
      "Step [4400/5760] Loss: 0.4401, Time: 636.8451\n",
      "Step [4500/5760] Loss: 0.5381, Time: 651.0553\n",
      "Step [4600/5760] Loss: 0.4814, Time: 665.3946\n",
      "Step [4700/5760] Loss: 0.4162, Time: 679.5139\n",
      "Step [4800/5760] Loss: 0.4279, Time: 693.9576\n",
      "Step [4900/5760] Loss: 0.3725, Time: 708.2129\n",
      "Step [5000/5760] Loss: 0.3958, Time: 722.5338\n",
      "Step [5100/5760] Loss: 1.0406, Time: 736.7709\n",
      "Step [5200/5760] Loss: 0.3968, Time: 751.1621\n",
      "Step [5300/5760] Loss: 0.5777, Time: 765.7104\n",
      "Step [5400/5760] Loss: 0.5124, Time: 780.6214\n",
      "Step [5500/5760] Loss: 0.8507, Time: 795.4246\n",
      "Step [5600/5760] Loss: 0.8585, Time: 810.1662\n",
      "Step [5700/5760] Loss: 0.3876, Time: 825.1975\n",
      "Test Summary: \n",
      "\tTest loss: 0.5310813541989774\n",
      "Restoring test skewers...\n"
     ]
    }
   ],
   "source": [
    "from scipy import optimize\n",
    "def norm_specs(skewers,redshift):\n",
    "    tauevo = 0.001845*(1+redshift)**3.924 #optical depth corresponding to the mean-flux of Faucher-Giguere et al. 2008 \n",
    "    fobs = np.exp(-tauevo)\n",
    "    def fun(a): return np.mean(np.exp(-a*skewers)-fobs)\n",
    "    a = optimize.newton(fun, 1)    \n",
    "    return a\n",
    "rs = 2.0020281392528516 #redshift of the snapshot\n",
    "\n",
    "\n",
    "# load model\n",
    "print('Loading model...')\n",
    "model = get_residual_network().float().to(device)\n",
    "model.load_state_dict(torch.load('params/params_%s.pkl'\\\n",
    "        %time.strftime(\"%Y-%m-%d_%H:%M:%S\", localtime)))\n",
    "'''\n",
    "model.load_state_dict(torch.load('params/HyPhy_%s'\\\n",
    "        %time.strftime(\"%Y-%m-%d_%H:%M:%S\", localtime)))\n",
    "'''\n",
    "\n",
    "\n",
    "# loss\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "\n",
    "# record starr time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# start test\n",
    "print('Begin testing...')\n",
    "test_outp, test_losses = test(test_ske, test_block, DM_general, DM_param,\n",
    "                        test_batch, train_insize, model, criterion, device, start_time)\n",
    "\n",
    "print(\"Test Summary: \")\n",
    "print(\"\\tTest loss: {}\".format(test_losses))\n",
    "\n",
    "# restore test skewers\n",
    "print('Restoring test skewers...')\n",
    "nz = (ske_len/train_ousize[2]).astype('int')\n",
    "test_outp = test_outp.reshape(-1, nz, train_ousize[0],\n",
    "                            train_ousize[1], train_ousize[2])\\\n",
    "                            .transpose(0, 2, 3, 1, 4).reshape(-1, ske_len)\n",
    "test_ske = test_ske.numpy().reshape(-1, nz, train_ousize[0],\n",
    "                            train_ousize[1], train_ousize[2])\\\n",
    "                            .transpose(0, 2, 3, 1, 4).reshape(-1, ske_len)\n",
    "test_FGPA = test_FGPA.numpy().reshape(-1, nz, train_ousize[0],\n",
    "                            train_ousize[1], train_ousize[2])\\\n",
    "                            .transpose(0, 2, 3, 1, 4).reshape(-1, ske_len)\n",
    "\n",
    "tau = np.exp(test_ske)\n",
    "F_hydro = np.exp(-tau)\n",
    "F_sum = F_hydro.sum(axis=1)\n",
    "limit = np.percentile(F_sum, 10)\n",
    "bln = F_sum >= limit\n",
    "tau = tau[bln]\n",
    "normalization = norm_specs(tau,rs) #determine the normalization constant on the whole tau box\n",
    "tau_normed = normalization*tau #normalized optical depth\n",
    "test_ske = np.exp(-normalization*tau) #normalized flux\n",
    "\n",
    "tau = np.exp(test_outp[bln])\n",
    "normalization = norm_specs(tau,rs) #determine the normalization constant on the whole tau box\n",
    "tau_normed = normalization*tau #normalized optical depth\n",
    "test_outp = np.exp(-normalization*tau) #normalized flux\n",
    "\n",
    "tau = np.exp(test_FGPA[bln])\n",
    "normalization = norm_specs(tau,rs) #determine the normalization constant on the whole tau box\n",
    "tau_normed = normalization*tau #normalized optical depth\n",
    "test_FGPA = np.exp(-normalization*tau) #normalized flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting example skewers...\n",
      "[0.87123835 0.87123901 0.87123984]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 6962 is out of bounds for axis 0 with size 3000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ead383e65d1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m         print('Plotting {:{}d}/{}, y{:03d}z{:03d}.png...'\\\n\u001b[1;32m     54\u001b[0m                 .format((i+1), int(np.log10(nrange)+1), nrange,\n\u001b[0;32m---> 55\u001b[0;31m                         test_block[ii,0], test_block[ii,1]))\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mtest_block_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_block\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 6962 is out of bounds for axis 0 with size 3000"
     ]
    }
   ],
   "source": [
    "'''\n",
    "test_outp = toF_proc(test_outp)\n",
    "test_ske  = toF_proc(test_ske)\n",
    "test_FGPA = toF_proc(test_FGPA)\n",
    "'''\n",
    "test_coord = test_block.reshape(-1, nz, 3)[:, 0, 0:2].T.reshape(2, 1, 1, -1)\n",
    "xcoor = np.arange(train_ousize[0]) - np.arange(train_ousize[0]).mean()\n",
    "ycoor = np.arange(train_ousize[1]) - np.arange(train_ousize[1]).mean()\n",
    "mesh  = np.expand_dims(np.array(np.meshgrid(xcoor, ycoor)), -1)\n",
    "test_block = (test_coord + mesh).transpose(3,2,1,0).reshape(-1, 2).astype(int)\n",
    "del test_coord, xcoor, ycoor, mesh\n",
    "\n",
    "\n",
    "print('Plotting example skewers...')\n",
    "# generate comparison images\n",
    "folder_outp = Path.cwd()/'test_figs'/('%s_x'\\\n",
    "        %time.strftime(\"%Y-%m-%d_%H:%M:%S_FGPA\", localtime))\n",
    "if not os.path.exists(folder_outp):\n",
    "    os.makedirs(folder_outp)\n",
    "\n",
    "\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "import astropy.units as u\n",
    "z = 2.0\n",
    "h= 0.704\n",
    "cosmo = FlatLambdaCDM(H0=100.0*h, Om0=0.2726, Ob0=0.0456)\n",
    "Hz = cosmo.H(z)\n",
    "a = 1.0 / (1.0 + z)\n",
    "v_end  = (a * Hz * 75/h*u.Mpc).to(u.km / u.s).value\n",
    "F_mean = np.array([test_ske.mean(), test_outp.mean(), test_FGPA.mean()])\n",
    "print(F_mean)\n",
    "\n",
    "nrange = min(len(test_ske), 200)\n",
    "test_sp = np.arange(len(test_ske))\n",
    "np.random.seed(99)\n",
    "np.random.shuffle(test_sp)\n",
    "test_sp1 = test_sp[:int(nrange)].astype('int')\n",
    "test_sp2 = test_sp[int(nrange):].astype('int')\n",
    "\n",
    "bins = int(15)\n",
    "accuracy = AverageMeter()\n",
    "rela_err = AverageMeter()\n",
    "accu_arr = np.zeros(shape=(len(test_ske), 2))\n",
    "erro_arr = np.zeros(shape=(len(test_ske), 2))\n",
    "oneDPS   = np.zeros(shape=(4, len(test_ske), bins))\n",
    "\n",
    "\n",
    "# loop\n",
    "import datetime\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "with PdfPages('Example_Skewers.pdf') as pdf:\n",
    "    for i, ii in enumerate(test_sp1):\n",
    "        print('Plotting {:{}d}/{}, y{:03d}z{:03d}.png...'\\\n",
    "                .format((i+1), int(np.log10(nrange)+1), nrange,\n",
    "                        test_block[ii,0], test_block[ii,1]))\n",
    "\n",
    "        test_block_i = test_block[ii]\n",
    "        test_outp_i = test_outp[ii]\n",
    "        test_ske_i = test_ske[ii]\n",
    "        test_FGPA_i = test_FGPA[ii]\n",
    "        test_DM_i = DM_general[0, test_block_i[0], test_block_i[1], :].numpy()\n",
    "\n",
    "        stat_i, fig = test_accuracy(test_block_i, test_outp_i, test_ske_i, test_FGPA_i,\n",
    "                          test_DM_i, F_mean, v_end, folder_outp, bins, plot=True)\n",
    "        accuracy_i, rela_err_i = stat_i[[4,5]]\n",
    "        accuracy.update(accuracy_i, 1)\n",
    "        rela_err.update(rela_err_i, 1)\n",
    "        accu_arr[ii] = accuracy_i\n",
    "        erro_arr[ii] = rela_err_i\n",
    "        oneDPS[:,ii] = stat_i[0], stat_i[1], stat_i[2], stat_i[3]\n",
    "    \n",
    "        pdf.savefig(fig)\n",
    "        \n",
    "    d = pdf.infodict()\n",
    "    d['Title'] = 'Example Skewers'\n",
    "    d['Author'] = 'Yi Kang'\n",
    "    #d['Subject'] = 'How to create a multipage pdf file and set its metadata'\n",
    "    #d['Keywords'] = 'PdfPages multipage keywords author title subject'\n",
    "    d['CreationDate'] = datetime.datetime.today()\n",
    "    d['ModDate'] = datetime.datetime.today()\n",
    "    \n",
    "print('Measuring accuracy of the rest skewers...')\n",
    "for i, ii in enumerate(test_sp2):\n",
    "\n",
    "    test_block_i = test_block[ii]\n",
    "    test_outp_i = test_outp[ii]\n",
    "    test_ske_i = test_ske[ii]\n",
    "    test_FGPA_i = test_FGPA[ii]\n",
    "    test_DM_i = DM_general[0, test_block_i[0], test_block_i[1], :].numpy()\n",
    "\n",
    "    stat_i = test_accuracy(test_block_i, test_outp_i, test_ske_i, test_FGPA_i,\n",
    "                      test_DM_i, F_mean, v_end, folder_outp, bins, plot=False)\n",
    "    accuracy_i, rela_err_i = stat_i[[4,5]]\n",
    "    accuracy.update(accuracy_i, 1)\n",
    "    rela_err.update(rela_err_i, 1)\n",
    "    accu_arr[ii] = accuracy_i\n",
    "    erro_arr[ii] = rela_err_i\n",
    "    oneDPS[:,ii] = stat_i[0], stat_i[1], stat_i[2], stat_i[3]\n",
    "\n",
    "\n",
    "print('Plotting average 1DPS and PDF...')\n",
    "oneDPS_backup = oneDPS\n",
    "oneDPS = oneDPS.mean(axis=1)\n",
    "oneDPS = oneDPS[~np.isnan(oneDPS)].reshape(4,-1)\n",
    "bln = oneDPS[0]<0.1\n",
    "accuracy_gen = np.abs((oneDPS[1]-oneDPS[2])/oneDPS[2])[bln].mean()\n",
    "rela_err_gen = np.abs((oneDPS[1]-oneDPS[2])/oneDPS[2])[bln].std()\n",
    "accuracy_FGPA = np.abs((oneDPS[3]-oneDPS[2])/oneDPS[2])[bln].mean()\n",
    "rela_err_FGPA = np.abs((oneDPS[3]-oneDPS[2])/oneDPS[2])[bln].std()\n",
    "\n",
    "outp_hist, F_hist = np.histogram(test_outp, bins=np.arange(0,1.05,0.05))\n",
    "test_hist, F_hist = np.histogram(test_ske,  bins=np.arange(0,1.05,0.05))\n",
    "FGPA_hist, F_hist = np.histogram(test_FGPA, bins=np.arange(0,1.05,0.05))\n",
    "outp_hist = np.append(outp_hist, outp_hist[-1]) / len(test_ske)\n",
    "test_hist = np.append(test_hist, test_hist[-1]) / len(test_ske)\n",
    "FGPA_hist = np.append(FGPA_hist, FGPA_hist[-1]) / len(test_ske)\n",
    "bln = (F_hist>=0.1) & (F_hist<0.9)\n",
    "accuracy_hist = np.abs((outp_hist-test_hist)/test_hist)[bln].mean()\n",
    "rela_err_hist = np.abs((outp_hist-test_hist)/test_hist)[bln].std()\n",
    "m_hist_FGPA = np.abs((FGPA_hist-test_hist)/test_hist)[bln].mean()\n",
    "s_hist_FGPA = np.abs((FGPA_hist-test_hist)/test_hist)[bln].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6962"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(2,2,figsize=(15,11))\n",
    "\n",
    "p0 = axes[0,0].hist(accu_arr[:,0], label='ML', bins=np.arange(0, 1.7, 0.1))\n",
    "axes[0,0].set_xlim(-0.1, 1.8)\n",
    "axes[0,0].set_ylim(axes[0,0].get_ylim())\n",
    "p1 = axes[0,0].vlines(x=np.median(accu_arr[:,0]), ymin=0, ymax=9999, linestyle='--')\n",
    "p9 = axes[0,0].hist(accu_arr[:,1], label='FGPA', color='tab:green', bins=np.arange(0, 1.7, 0.1), alpha=0.5)\n",
    "axes[0,0].set_xlabel('accuracy $m$', fontsize=14)\n",
    "axes[0,0].set_title('pdf of $m$', fontsize=14)\n",
    "axes[0,0].tick_params(labelsize=12, direction='in')\n",
    "customs = [p1, \n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                  markerfacecolor='k', markersize=5),\n",
    "          p9]\n",
    "axes[0,0].legend(customs, ['median $m=%.4f$'%np.median(accu_arr),\n",
    "                        '$N=%d$'%len(accu_arr)], fontsize=12, loc=1)\n",
    "\n",
    "axes[0,1].hist(erro_arr[0], color='grey', bins=np.arange(0, 1.7, 0.1))\n",
    "axes[0,1].set_xlim(-0.1, 1.8)\n",
    "axes[0,1].set_ylim(axes[0,1].get_ylim())\n",
    "p2 = axes[0,1].vlines(x=erro_arr.mean(), ymin=0, ymax=9999, linestyle='--')\n",
    "axes[0,1].set_xlabel('error $s$', fontsize=14)\n",
    "axes[0,1].set_title('pdf of $s$', fontsize=14)\n",
    "axes[0,1].tick_params(labelsize=12, direction='in')\n",
    "customs = [p2, \n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                  markerfacecolor='k', markersize=5)]\n",
    "axes[0,1].legend(customs, ['average $s=%.4f$'%erro_arr.mean(),\n",
    "                        '$N=%d$'%len(erro_arr)], fontsize=12, loc=1)\n",
    "\n",
    "p3, = axes[1,0].plot(oneDPS[0], oneDPS[1], label='ML')\n",
    "p4, = axes[1,0].plot(oneDPS[0], oneDPS[2], label='Hydro', alpha=0.5)\n",
    "p7, = axes[1,0].plot(oneDPS[0], oneDPS[3], label='FGPA', alpha=0.5)\n",
    "axes[1,0].set_xlabel(r'$k\\ (\\mathrm{s/km})$', fontsize=14)\n",
    "axes[1,0].set_ylabel(r'$kP_\\mathrm{1D}/\\pi$', fontsize=14)\n",
    "axes[1,0].set_xscale('log')\n",
    "axes[1,0].set_yscale('log')\n",
    "axes[1,0].set_ylim(axes[1,0].get_ylim())\n",
    "axes[1,0].vlines(x=0.1, ymin=1e-8, ymax=1e8)\n",
    "axes[1,0].set_title('Average 1DPS', fontsize=14)\n",
    "axes[1,0].tick_params(labelsize=12, direction='in', which='both')\n",
    "customs = [p3,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p7,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p4]\n",
    "axes[1,0].legend(customs, [p3.get_label(), '$m=%.3f$'%accuracy_gen, '$s=%.3f$'%rela_err_gen, \n",
    "                    p7.get_label(),'$m=%.3f$'%accuracy_FGPA, '$s=%.3f$'%rela_err_FGPA,\n",
    "                    p4.get_label()], fontsize=12)\n",
    "\n",
    "p5, = axes[1,1].step(F_hist, outp_hist, where='post', label='ML')\n",
    "p6, = axes[1,1].step(F_hist, test_hist, where='post', label='Hydro', alpha=0.5)\n",
    "p8, = axes[1,1].step(F_hist, FGPA_hist, where='post', label='FGPA', alpha=0.5)\n",
    "axes[1,1].set_xlabel(r'$F$', fontsize=18)\n",
    "axes[1,1].set_ylabel(r'Counts', fontsize=18)\n",
    "axes[1,1].set_xlim([0, 1])\n",
    "axes[1,1].set_ylim(bottom=0)\n",
    "axes[1,1].vlines(x=0.1, ymin=0, ymax=6000)\n",
    "axes[1,1].vlines(x=0.9, ymin=0, ymax=6000)\n",
    "axes[1,1].set_title('Average PDF of $F$', fontsize=14)\n",
    "axes[1,1].tick_params(labelsize=12, direction='in')\n",
    "customs = [p5,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p8,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p6]\n",
    "axes[1,1].legend(customs, [p5.get_label(), '$m=%.3f$'%accuracy_hist, '$s=%.3f$'%rela_err_hist,\n",
    "                    p8.get_label(),'$m=%.3f$'%m_hist_FGPA, '$s=%.3f$'%s_hist_FGPA,\n",
    "                    p6.get_label()], fontsize=12)\n",
    "\n",
    "#plt.savefig(folder_outp / ('average.png'), dpi=300, bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = 4\n",
    "vaxis = np.arange(ske_len)/ske_len * v_end\n",
    "order = np.random.randint(len(test_ske), size=examples)\n",
    "\n",
    "fig, axes = plt.subplots(examples,1,figsize=(12,examples*2.4))\n",
    "\n",
    "for i in range(examples):\n",
    "    axes[i].plot(vaxis, test_outp[order[i]], label='ML',  alpha=0.7)\n",
    "    axes[i].plot(vaxis, test_FGPA[order[i]], label='FGPA', color='tab:green', alpha=0.5)\n",
    "    axes[i].plot(vaxis, test_ske[order[i]], label='Hydro', color='tab:orange', alpha=0.7)\n",
    "    axes[i].set_xlim([0, max(vaxis)])\n",
    "    axes[i].set_ylim([0,1])\n",
    "    axes[i].set_yticklabels([0.0, 0.2, 0.4, 0.6, 0.8])\n",
    "    axes[i].set_ylabel(r'$F$', fontsize=18, labelpad=0.5)\n",
    "    if i != int(examples-1):\n",
    "        axes[i].set_xticklabels([])\n",
    "axes[0].set_yticklabels([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "axes[-1].set_xlabel(r'$v$ (km/s)', fontsize=18, labelpad=0.5)\n",
    "axes[-1].legend(fontsize=18, bbox_to_anchor=(1.25,2.75))\n",
    "plt.subplots_adjust(hspace=0)\n",
    "#plt.savefig(folder_outp / ('examples.png'), dpi=600, bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_deviation = (oneDPS[2] - oneDPS[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneDPS_backup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneDPS_deviation = (oneDPS_backup[2] - oneDPS_backup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bln = oneDPS_deviation[:,0] > final_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = np.exp(test_ske)\n",
    "F_hydro = np.exp(-tau)\n",
    "F_sum = F_hydro.sum(axis=1)\n",
    "limit = np.percentile(F_sum, 20)\n",
    "bln = F_sum >= limit\n",
    "tau = tau[bln]\n",
    "normalization = norm_specs(tau,rs) #determine the normalization constant on the whole tau box\n",
    "tau_normed = normalization*tau #normalized optical depth\n",
    "test_ske = np.exp(-normalization*tau) #normalized flux\n",
    "\n",
    "tau = np.exp(test_outp[bln])\n",
    "normalization = norm_specs(tau,rs) #determine the normalization constant on the whole tau box\n",
    "tau_normed = normalization*tau #normalized optical depth\n",
    "test_outp = np.exp(-normalization*tau) #normalized flux\n",
    "\n",
    "tau = np.exp(test_FGPA[bln])\n",
    "normalization = norm_specs(tau,rs) #determine the normalization constant on the whole tau box\n",
    "tau_normed = normalization*tau #normalized optical depth\n",
    "test_FGPA = np.exp(-normalization*tau) #normalized flux\n",
    "'''\n",
    "test_outp = toF_proc(test_outp)\n",
    "test_ske  = toF_proc(test_ske)\n",
    "test_FGPA = toF_proc(test_FGPA)\n",
    "'''\n",
    "test_coord = test_block.reshape(-1, nz, 3)[:, 0, 0:2].T.reshape(2, 1, 1, -1)\n",
    "xcoor = np.arange(train_ousize[0]) - np.arange(train_ousize[0]).mean()\n",
    "ycoor = np.arange(train_ousize[1]) - np.arange(train_ousize[1]).mean()\n",
    "mesh  = np.expand_dims(np.array(np.meshgrid(xcoor, ycoor)), -1)\n",
    "test_block = (test_coord + mesh).transpose(3,2,1,0).reshape(-1, 2).astype(int)\n",
    "del test_coord, xcoor, ycoor, mesh\n",
    "\n",
    "\n",
    "print('Plotting example skewers...')\n",
    "# generate comparison images\n",
    "folder_outp = Path.cwd()/'test_figs'/('%s_x'\\\n",
    "        %time.strftime(\"%Y-%m-%d_%H:%M:%S_FGPA\", localtime))\n",
    "if not os.path.exists(folder_outp):\n",
    "    os.makedirs(folder_outp)\n",
    "\n",
    "\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "import astropy.units as u\n",
    "z = 2.0\n",
    "h= 0.704\n",
    "cosmo = FlatLambdaCDM(H0=100.0*h, Om0=0.2726, Ob0=0.0456)\n",
    "Hz = cosmo.H(z)\n",
    "a = 1.0 / (1.0 + z)\n",
    "v_end  = (a * Hz * 75/h*u.Mpc).to(u.km / u.s).value\n",
    "F_mean = np.array([test_ske.mean(), test_outp.mean(), test_FGPA.mean()])\n",
    "print(F_mean)\n",
    "\n",
    "nrange = min(len(test_ske), 50)\n",
    "test_sp = np.arange(len(test_ske))\n",
    "np.random.seed(99)\n",
    "np.random.shuffle(test_sp)\n",
    "test_sp1 = test_sp[:int(nrange)].astype('int')\n",
    "test_sp2 = test_sp[int(nrange):].astype('int')\n",
    "\n",
    "bins = int(15)\n",
    "accuracy = AverageMeter()\n",
    "rela_err = AverageMeter()\n",
    "accu_arr = np.zeros(shape=(len(test_ske), 2))\n",
    "erro_arr = np.zeros(shape=(len(test_ske), 2))\n",
    "oneDPS   = np.zeros(shape=(4, len(test_ske), bins))\n",
    "\n",
    "\n",
    "# loop\n",
    "for i, ii in enumerate(test_sp1):\n",
    "    print('Plotting {:{}d}/{}, y{:03d}z{:03d}.png...'\\\n",
    "            .format((i+1), int(np.log10(nrange)+1), nrange,\n",
    "                    test_block[ii,0], test_block[ii,1]))\n",
    "\n",
    "    test_block_i = test_block[ii]\n",
    "    test_outp_i = test_outp[ii]\n",
    "    test_ske_i = test_ske[ii]\n",
    "    test_FGPA_i = test_FGPA[ii]\n",
    "    test_DM_i = DM_general[0, test_block_i[0], test_block_i[1], :].numpy()\n",
    "\n",
    "    stat_i = test_accuracy(test_block_i, test_outp_i, test_ske_i, test_FGPA_i,\n",
    "                      test_DM_i, F_mean, v_end, folder_outp, bins, plot=True)\n",
    "    accuracy_i, rela_err_i = stat_i[[4,5]]\n",
    "    accuracy.update(accuracy_i, 1)\n",
    "    rela_err.update(rela_err_i, 1)\n",
    "    accu_arr[ii] = accuracy_i\n",
    "    erro_arr[ii] = rela_err_i\n",
    "    oneDPS[:,ii] = stat_i[0], stat_i[1], stat_i[2], stat_i[3]\n",
    "\n",
    "print('Measuring accuracy of the rest skewers...')\n",
    "for i, ii in enumerate(test_sp2):\n",
    "\n",
    "    test_block_i = test_block[ii]\n",
    "    test_outp_i = test_outp[ii]\n",
    "    test_ske_i = test_ske[ii]\n",
    "    test_FGPA_i = test_FGPA[ii]\n",
    "    test_DM_i = DM_general[0, test_block_i[0], test_block_i[1], :].numpy()\n",
    "\n",
    "    stat_i = test_accuracy(test_block_i, test_outp_i, test_ske_i, test_FGPA_i,\n",
    "                      test_DM_i, F_mean, v_end, folder_outp, bins, plot=False)\n",
    "    accuracy_i, rela_err_i = stat_i[[4,5]]\n",
    "    accuracy.update(accuracy_i, 1)\n",
    "    rela_err.update(rela_err_i, 1)\n",
    "    accu_arr[ii] = accuracy_i\n",
    "    erro_arr[ii] = rela_err_i\n",
    "    oneDPS[:,ii] = stat_i[0], stat_i[1], stat_i[2], stat_i[3]\n",
    "\n",
    "\n",
    "print('Plotting average 1DPS and PDF...')\n",
    "oneDPS_backup = oneDPS\n",
    "oneDPS = oneDPS.mean(axis=1)\n",
    "oneDPS = oneDPS[~np.isnan(oneDPS)].reshape(4,-1)\n",
    "bln = oneDPS[0]<0.1\n",
    "accuracy_gen = np.abs((oneDPS[1]-oneDPS[2])/oneDPS[2])[bln].mean()\n",
    "rela_err_gen = np.abs((oneDPS[1]-oneDPS[2])/oneDPS[2])[bln].std()\n",
    "accuracy_FGPA = np.abs((oneDPS[3]-oneDPS[2])/oneDPS[2])[bln].mean()\n",
    "rela_err_FGPA = np.abs((oneDPS[3]-oneDPS[2])/oneDPS[2])[bln].std()\n",
    "\n",
    "outp_hist, F_hist = np.histogram(test_outp, bins=np.arange(0,1.05,0.05))\n",
    "test_hist, F_hist = np.histogram(test_ske,  bins=np.arange(0,1.05,0.05))\n",
    "FGPA_hist, F_hist = np.histogram(test_FGPA, bins=np.arange(0,1.05,0.05))\n",
    "outp_hist = np.append(outp_hist, outp_hist[-1]) / len(test_ske)\n",
    "test_hist = np.append(test_hist, test_hist[-1]) / len(test_ske)\n",
    "FGPA_hist = np.append(FGPA_hist, FGPA_hist[-1]) / len(test_ske)\n",
    "bln = (F_hist>=0.1) & (F_hist<0.9)\n",
    "accuracy_hist = np.abs((outp_hist-test_hist)/test_hist)[bln].mean()\n",
    "rela_err_hist = np.abs((outp_hist-test_hist)/test_hist)[bln].std()\n",
    "m_hist_FGPA = np.abs((FGPA_hist-test_hist)/test_hist)[bln].mean()\n",
    "s_hist_FGPA = np.abs((FGPA_hist-test_hist)/test_hist)[bln].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(2,2,figsize=(15,11))\n",
    "\n",
    "p0 = axes[0,0].hist(accu_arr[:,0], label='ML', bins=np.arange(0, 1.7, 0.1))\n",
    "axes[0,0].set_xlim(-0.1, 1.8)\n",
    "axes[0,0].set_ylim(axes[0,0].get_ylim())\n",
    "p1 = axes[0,0].vlines(x=np.median(accu_arr[:,0]), ymin=0, ymax=9999, linestyle='--')\n",
    "p9 = axes[0,0].hist(accu_arr[:,1], label='FGPA', color='tab:green', bins=np.arange(0, 1.7, 0.1), alpha=0.5)\n",
    "axes[0,0].set_xlabel('accuracy $m$', fontsize=14)\n",
    "axes[0,0].set_title('pdf of $m$', fontsize=14)\n",
    "axes[0,0].tick_params(labelsize=12, direction='in')\n",
    "customs = [p1, \n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                  markerfacecolor='k', markersize=5),\n",
    "          p9]\n",
    "axes[0,0].legend(customs, ['median $m=%.4f$'%np.median(accu_arr[:,0]),\n",
    "                        '$N=%d$'%len(accu_arr)], fontsize=12, loc=1)\n",
    "\n",
    "axes[0,1].hist(erro_arr[:,0], color='grey', bins=np.arange(0, 1.7, 0.1))\n",
    "axes[0,1].set_xlim(-0.1, 1.8)\n",
    "axes[0,1].set_ylim(axes[0,1].get_ylim())\n",
    "p2 = axes[0,1].vlines(x=np.median(erro_arr[:,0]), ymin=0, ymax=9999, linestyle='--')\n",
    "axes[0,1].set_xlabel('error $s$', fontsize=14)\n",
    "axes[0,1].set_title('pdf of $s$', fontsize=14)\n",
    "axes[0,1].tick_params(labelsize=12, direction='in')\n",
    "customs = [p2, \n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                  markerfacecolor='k', markersize=5)]\n",
    "axes[0,1].legend(customs, ['median $s=%.4f$'%np.median(erro_arr[:,0]),\n",
    "                        '$N=%d$'%len(erro_arr)], fontsize=12, loc=1)\n",
    "\n",
    "p3, = axes[1,0].plot(oneDPS[0], oneDPS[1], label='ML')\n",
    "p4, = axes[1,0].plot(oneDPS[0], oneDPS[2], label='Hydro', alpha=0.5)\n",
    "p7, = axes[1,0].plot(oneDPS[0], oneDPS[3], label='FGPA', alpha=0.5)\n",
    "axes[1,0].set_xlabel(r'$k\\ (\\mathrm{s/km})$', fontsize=14)\n",
    "axes[1,0].set_ylabel(r'$kP_\\mathrm{1D}/\\pi$', fontsize=14)\n",
    "axes[1,0].set_xscale('log')\n",
    "axes[1,0].set_yscale('log')\n",
    "axes[1,0].set_ylim(axes[1,0].get_ylim())\n",
    "axes[1,0].vlines(x=0.1, ymin=1e-8, ymax=1e8)\n",
    "axes[1,0].set_title('Average 1DPS', fontsize=14)\n",
    "axes[1,0].tick_params(labelsize=12, direction='in', which='both')\n",
    "customs = [p3,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p7,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p4]\n",
    "axes[1,0].legend(customs, [p3.get_label(), '$m=%.3f$'%accuracy_gen, '$s=%.3f$'%rela_err_gen, \n",
    "                    p7.get_label(),'$m=%.3f$'%accuracy_FGPA, '$s=%.3f$'%rela_err_FGPA,\n",
    "                    p4.get_label()], fontsize=12)\n",
    "\n",
    "p5, = axes[1,1].step(F_hist, outp_hist, where='post', label='ML')\n",
    "p6, = axes[1,1].step(F_hist, test_hist, where='post', label='Hydro', alpha=0.5)\n",
    "p8, = axes[1,1].step(F_hist, FGPA_hist, where='post', label='FGPA', alpha=0.5)\n",
    "axes[1,1].set_xlabel(r'$F$', fontsize=18)\n",
    "axes[1,1].set_ylabel(r'Counts', fontsize=18)\n",
    "axes[1,1].set_xlim([0, 1])\n",
    "axes[1,1].set_ylim(bottom=0)\n",
    "axes[1,1].vlines(x=0.1, ymin=0, ymax=6000)\n",
    "axes[1,1].vlines(x=0.9, ymin=0, ymax=6000)\n",
    "axes[1,1].set_title('Average PDF of $F$', fontsize=14)\n",
    "axes[1,1].tick_params(labelsize=12, direction='in')\n",
    "customs = [p5,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p8,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p6]\n",
    "axes[1,1].legend(customs, [p5.get_label(), '$m=%.3f$'%accuracy_hist, '$s=%.3f$'%rela_err_hist,\n",
    "                    p8.get_label(),'$m=%.3f$'%m_hist_FGPA, '$s=%.3f$'%s_hist_FGPA,\n",
    "                    p6.get_label()], fontsize=12)\n",
    "\n",
    "#plt.savefig(folder_outp / ('average.png'), dpi=300, bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "def norm_specs(skewers,redshift):\n",
    "    tauevo = 0.001845*(1+redshift)**3.924 #optical depth corresponding to the mean-flux of Faucher-Giguere et al. 2008 \n",
    "    fobs = np.exp(-tauevo)\n",
    "    def fun(a): return np.mean(np.exp(-a*skewers)-fobs)\n",
    "    a = optimize.newton(fun, 1)    \n",
    "    return a\n",
    "rs = 2.0020281392528516 #redshift of the snapshot\n",
    "\n",
    "\n",
    "# load model\n",
    "print('Loading model...')\n",
    "model = get_residual_network().float().to(device)\n",
    "model.load_state_dict(torch.load('params/params_%s.pkl'\\\n",
    "        %time.strftime(\"%Y-%m-%d_%H:%M:%S\", localtime)))\n",
    "'''\n",
    "model.load_state_dict(torch.load('params/HyPhy_%s'\\\n",
    "        %time.strftime(\"%Y-%m-%d_%H:%M:%S\", localtime)))\n",
    "'''\n",
    "\n",
    "\n",
    "# loss\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "\n",
    "# record starr time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# start test\n",
    "print('Begin testing...')\n",
    "test_outp, test_losses = test(test_ske, test_block, DM_general, DM_param,\n",
    "                        test_batch, train_insize, model, criterion, device, start_time)\n",
    "\n",
    "print(\"Test Summary: \")\n",
    "print(\"\\tTest loss: {}\".format(test_losses))\n",
    "\n",
    "# restore test skewers\n",
    "print('Restoring test skewers...')\n",
    "nz = (ske_len/train_ousize[2]).astype('int')\n",
    "test_outp = test_outp.reshape(-1, nz, train_ousize[0],\n",
    "                            train_ousize[1], train_ousize[2])\\\n",
    "                            .transpose(0, 2, 3, 1, 4).reshape(-1, ske_len)\n",
    "test_ske = test_ske.numpy().reshape(-1, nz, train_ousize[0],\n",
    "                            train_ousize[1], train_ousize[2])\\\n",
    "                            .transpose(0, 2, 3, 1, 4).reshape(-1, ske_len)\n",
    "test_FGPA = test_FGPA.numpy().reshape(-1, nz, train_ousize[0],\n",
    "                            train_ousize[1], train_ousize[2])\\\n",
    "                            .transpose(0, 2, 3, 1, 4).reshape(-1, ske_len)\n",
    "\n",
    "test_outp = toF_proc(test_outp)\n",
    "test_ske  = toF_proc(test_ske)\n",
    "test_FGPA = toF_proc(test_FGPA)\n",
    "\n",
    "test_coord = test_block.reshape(-1, nz, 3)[:, 0, 0:2].T.reshape(2, 1, 1, -1)\n",
    "xcoor = np.arange(train_ousize[0]) - np.arange(train_ousize[0]).mean()\n",
    "ycoor = np.arange(train_ousize[1]) - np.arange(train_ousize[1]).mean()\n",
    "mesh  = np.expand_dims(np.array(np.meshgrid(xcoor, ycoor)), -1)\n",
    "test_block = (test_coord + mesh).transpose(3,2,1,0).reshape(-1, 2).astype(int)\n",
    "del test_coord, xcoor, ycoor, mesh\n",
    "\n",
    "\n",
    "print('Plotting example skewers...')\n",
    "# generate comparison images\n",
    "folder_outp = Path.cwd()/'test_figs'/('%s_x'\\\n",
    "        %time.strftime(\"%Y-%m-%d_%H:%M:%S_FGPA\", localtime))\n",
    "if not os.path.exists(folder_outp):\n",
    "    os.makedirs(folder_outp)\n",
    "\n",
    "\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "import astropy.units as u\n",
    "z = 2.0\n",
    "h= 0.704\n",
    "cosmo = FlatLambdaCDM(H0=100.0*h, Om0=0.2726, Ob0=0.0456)\n",
    "Hz = cosmo.H(z)\n",
    "a = 1.0 / (1.0 + z)\n",
    "v_end  = (a * Hz * 75/h*u.Mpc).to(u.km / u.s).value\n",
    "F_mean = np.array([test_ske.mean(), test_outp.mean(), test_FGPA.mean()])\n",
    "print(F_mean)\n",
    "\n",
    "nrange = min(len(test_ske), 50)\n",
    "test_sp = np.arange(len(test_ske))\n",
    "np.random.seed(99)\n",
    "np.random.shuffle(test_sp)\n",
    "test_sp1 = test_sp[:int(nrange)].astype('int')\n",
    "test_sp2 = test_sp[int(nrange):].astype('int')\n",
    "\n",
    "bins = int(15)\n",
    "accuracy = AverageMeter()\n",
    "rela_err = AverageMeter()\n",
    "accu_arr = np.zeros(len(test_ske))\n",
    "erro_arr = np.zeros(len(test_ske))\n",
    "oneDPS   = np.zeros(shape=(4, len(test_ske), bins))\n",
    "\n",
    "\n",
    "# loop\n",
    "for i, ii in enumerate(test_sp1):\n",
    "    print('Plotting {:{}d}/{}, y{:03d}z{:03d}.png...'\\\n",
    "            .format((i+1), int(np.log10(nrange)+1), nrange,\n",
    "                    test_block[ii,0], test_block[ii,1]))\n",
    "\n",
    "    test_block_i = test_block[ii]\n",
    "    test_outp_i = test_outp[ii]\n",
    "    test_ske_i = test_ske[ii]\n",
    "    test_FGPA_i = test_FGPA[ii]\n",
    "    test_DM_i = DM_general[0, test_block_i[0], test_block_i[1], :].numpy()\n",
    "\n",
    "    stat_i = test_plot(test_block_i, test_outp_i, test_ske_i, test_FGPA_i,\n",
    "                      test_DM_i, F_mean, v_end, folder_outp, bins)\n",
    "    accuracy_i, rela_err_i = stat_i[[4,5]]\n",
    "    accuracy.update(accuracy_i, 1)\n",
    "    rela_err.update(rela_err_i, 1)\n",
    "    accu_arr[ii] = accuracy_i\n",
    "    erro_arr[ii] = rela_err_i\n",
    "    oneDPS[:,ii] = stat_i[0], stat_i[1], stat_i[2], stat_i[3]\n",
    "\n",
    "print('Measuring accuracy of the left skewers...')\n",
    "for i, ii in enumerate(test_sp2):\n",
    "\n",
    "    test_block_i = test_block[ii]\n",
    "    test_outp_i = test_outp[ii]\n",
    "    test_ske_i = test_ske[ii]\n",
    "    test_FGPA_i = test_FGPA[ii]\n",
    "    test_DM_i = DM_general[0, test_block_i[0], test_block_i[1], :].numpy()\n",
    "\n",
    "    stat_i = test_accuracy(test_block_i, test_outp_i, test_ske_i, test_FGPA_i,\n",
    "                          F_mean, v_end, folder_outp, bins)\n",
    "    accuracy_i, rela_err_i = stat_i[[4,5]]\n",
    "    accuracy.update(accuracy_i, 1)\n",
    "    rela_err.update(rela_err_i, 1)\n",
    "    accu_arr[ii] = accuracy_i\n",
    "    erro_arr[ii] = rela_err_i\n",
    "    oneDPS[:,ii] = stat_i[0], stat_i[1], stat_i[2], stat_i[3]\n",
    "\n",
    "\n",
    "print('Plotting average 1DPS and PDF...')\n",
    "#oneDPS_backup = oneDPS\n",
    "oneDPS = oneDPS.mean(axis=1)\n",
    "oneDPS = oneDPS[~np.isnan(oneDPS)].reshape(4,-1)\n",
    "bln = oneDPS[0]<0.1\n",
    "accuracy_gen = np.abs((oneDPS[1]-oneDPS[2])/oneDPS[2])[bln].mean()\n",
    "rela_err_gen = np.abs((oneDPS[1]-oneDPS[2])/oneDPS[2])[bln].std()\n",
    "accuracy_FGPA = np.abs((oneDPS[3]-oneDPS[2])/oneDPS[2])[bln].mean()\n",
    "rela_err_FGPA = np.abs((oneDPS[3]-oneDPS[2])/oneDPS[2])[bln].std()\n",
    "\n",
    "outp_hist, F_hist = np.histogram(test_outp, bins=np.arange(0,1.05,0.05))\n",
    "test_hist, F_hist = np.histogram(test_ske,  bins=np.arange(0,1.05,0.05))\n",
    "FGPA_hist, F_hist = np.histogram(test_FGPA, bins=np.arange(0,1.05,0.05))\n",
    "outp_hist = np.append(outp_hist, outp_hist[-1]) / len(test_ske)\n",
    "test_hist = np.append(test_hist, test_hist[-1]) / len(test_ske)\n",
    "FGPA_hist = np.append(FGPA_hist, FGPA_hist[-1]) / len(test_ske)\n",
    "bln = (F_hist>=0.1) & (F_hist<0.9)\n",
    "accuracy_hist = np.abs((outp_hist-test_hist)/test_hist)[bln].mean()\n",
    "rela_err_hist = np.abs((outp_hist-test_hist)/test_hist)[bln].std()\n",
    "m_hist_FGPA = np.abs((FGPA_hist-test_hist)/test_hist)[bln].mean()\n",
    "s_hist_FGPA = np.abs((FGPA_hist-test_hist)/test_hist)[bln].std()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2,2,figsize=(15,11))\n",
    "\n",
    "p0=axes[0,0].hist(accu_arr, color='grey', bins=np.arange(0, 1.7, 0.1))\n",
    "axes[0,0].set_xlim(-0.1, 1.8)\n",
    "axes[0,0].set_ylim(axes[0,0].get_ylim())\n",
    "p1 = axes[0,0].vlines(x=accu_arr.mean(), ymin=0, ymax=9999, linestyle='--')\n",
    "axes[0,0].set_xlabel('accuracy $m$', fontsize=14)\n",
    "axes[0,0].set_title('pdf of $m$', fontsize=14)\n",
    "axes[0,0].tick_params(labelsize=12, direction='in')\n",
    "customs = [p1, \n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                  markerfacecolor='k', markersize=5)]\n",
    "axes[0,0].legend(customs, ['average $m=%.4f$'%accu_arr.mean(),\n",
    "                        '$N=%d$'%len(accu_arr)], fontsize=12, loc=1)\n",
    "\n",
    "axes[0,1].hist(erro_arr, color='grey', bins=np.arange(0, 1.7, 0.1))\n",
    "axes[0,1].set_xlim(-0.1, 1.8)\n",
    "axes[0,1].set_ylim(axes[0,1].get_ylim())\n",
    "p2 = axes[0,1].vlines(x=erro_arr.mean(), ymin=0, ymax=9999, linestyle='--')\n",
    "axes[0,1].set_xlabel('error $s$', fontsize=14)\n",
    "axes[0,1].set_title('pdf of $s$', fontsize=14)\n",
    "axes[0,1].tick_params(labelsize=12, direction='in')\n",
    "customs = [p2, \n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                  markerfacecolor='k', markersize=5)]\n",
    "axes[0,1].legend(customs, ['average $s=%.4f$'%erro_arr.mean(),\n",
    "                        '$N=%d$'%len(erro_arr)], fontsize=12, loc=1)\n",
    "\n",
    "p3, = axes[1,0].plot(oneDPS[0], oneDPS[1], label='Predicted')\n",
    "p4, = axes[1,0].plot(oneDPS[0], oneDPS[2], label='Real', alpha=0.5)\n",
    "p7, = axes[1,0].plot(oneDPS[0], oneDPS[3], label='FGPA', alpha=0.5)\n",
    "axes[1,0].set_xlabel(r'$k\\ (\\mathrm{s/km})$', fontsize=14)\n",
    "axes[1,0].set_ylabel(r'$kP_\\mathrm{1D}/\\pi$', fontsize=14)\n",
    "axes[1,0].set_xscale('log')\n",
    "axes[1,0].set_yscale('log')\n",
    "axes[1,0].set_ylim(axes[1,0].get_ylim())\n",
    "axes[1,0].vlines(x=0.1, ymin=1e-8, ymax=1e8)\n",
    "axes[1,0].set_title('Average 1DPS', fontsize=14)\n",
    "axes[1,0].tick_params(labelsize=12, direction='in', which='both')\n",
    "customs = [p3,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p7,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p4]\n",
    "axes[1,0].legend(customs, [p3.get_label(), '$m=%.3f$'%accuracy_gen, '$s=%.3f$'%rela_err_gen, \n",
    "                    p7.get_label(),'$m=%.3f$'%accuracy_FGPA, '$s=%.3f$'%rela_err_FGPA,\n",
    "                    p4.get_label()], fontsize=12)\n",
    "\n",
    "p5, = axes[1,1].step(F_hist, outp_hist, where='post', label='Predicted')\n",
    "p6, = axes[1,1].step(F_hist, test_hist, where='post', label='Real', alpha=0.5)\n",
    "p8, = axes[1,1].step(F_hist, FGPA_hist, where='post', label='FGPA', alpha=0.5)\n",
    "axes[1,1].set_xlabel(r'$F$', fontsize=18)\n",
    "axes[1,1].set_ylabel(r'Counts', fontsize=18)\n",
    "axes[1,1].set_xlim([0, 1])\n",
    "axes[1,1].set_ylim(bottom=0)\n",
    "axes[1,1].vlines(x=0.1, ymin=0, ymax=6000)\n",
    "axes[1,1].vlines(x=0.9, ymin=0, ymax=6000)\n",
    "axes[1,1].set_title('Average PDF of $F$', fontsize=14)\n",
    "axes[1,1].tick_params(labelsize=12, direction='in')\n",
    "customs = [p5,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p8,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p6]\n",
    "axes[1,1].legend(customs, [p5.get_label(), '$m=%.3f$'%accuracy_hist, '$s=%.3f$'%rela_err_hist,\n",
    "                    p8.get_label(),'$m=%.3f$'%m_hist_FGPA, '$s=%.3f$'%s_hist_FGPA,\n",
    "                    p6.get_label()], fontsize=12)\n",
    "\n",
    "#plt.savefig(folder_outp / ('average.png'), dpi=300, bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is unnormalized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
