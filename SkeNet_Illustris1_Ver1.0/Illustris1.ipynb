{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from data_loader import *\n",
    "from model import *\n",
    "from test import *\n",
    "\n",
    "\n",
    "# pre-process\n",
    "def pre_proc(tau, block):\n",
    "    '''log(tau), 95%'''\n",
    "    tau_sum = tau.sum(axis=(-1,-2,-3))\n",
    "    limit = np.percentile(tau_sum, 95)\n",
    "    bln = np.ones(len(tau), 'bool')#tau_sum <= limit\n",
    "    tau = np.log(tau)\n",
    "    return (tau[bln],  block[bln])\n",
    "\n",
    "def toF_proc(tau):\n",
    "    '''transfer data derived from pre_proc to F=exp(-tau)'''\n",
    "    tau = np.exp(-np.exp(tau))\n",
    "    return tau\n",
    "\n",
    "def load_FGPA(FGPA, train_ousize, DM_param):\n",
    "    nx, ny, nz = (DM_param.pix / train_ousize).astype('int')\n",
    "    FGPA = FGPA.reshape(nx, train_ousize[0], ny, train_ousize[1], DM_param.pix)\\\n",
    "        .transpose(0, 2, 1, 3, 4).reshape(-1, train_ousize[0], train_ousize[1], DM_param.pix)\n",
    "\n",
    "    x = (np.arange(nx)*(train_ousize[0]) + (train_ousize[0]-1)/2)\n",
    "    y = (np.arange(ny)*(train_ousize[1]) + (train_ousize[1]-1)/2)\n",
    "    z = (np.arange(nz)*(train_ousize[2]) + (train_ousize[2]-1)/2)\n",
    "    \n",
    "    cx = x.repeat(ny*nz).reshape(nx,ny,nz).transpose(0,1,2).flatten()\n",
    "    cy = y.repeat(nz*nx).reshape(ny,nz,nx).transpose(2,0,1).flatten()\n",
    "    cz = z.repeat(nx*ny).reshape(nz,nx,ny).transpose(1,2,0).flatten()\n",
    "    block = np.array([cx, cy, cz]).T.reshape(-1, nz, 3)\n",
    "\n",
    "    return FGPA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Path and data file name\n",
    "folder  = Path.cwd().parent / 'Illustris1'\n",
    "DM_name = ['deltaDM_Illustris1_L75_N600_v2.fits', \n",
    "            'vx_DM_Illustris1_L75_N600.fits',\n",
    "            'vy_DM_Illustris1_L75_N600.fits',\n",
    "            'vz_DM_Illustris1_L75_N600.fits']\n",
    "ske_name = 'spectra_Illustris1_N600_xaxis.npy'\n",
    "FGPA_name = 'tau_normed_FGPA_smooth250kpc_therbr_RSD_Illustris-1_snap68_L75_N600_cic_xaxis.fits'\n",
    "\n",
    "\n",
    "\n",
    "# hyper parameters\n",
    "train_insize = np.array([11, 11, 141]) # x, y, z respctively\n",
    "train_ousize = np.array([1, 1, 75]) # x, y, z respctively\n",
    "test_batch = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: Quadro P6000\n",
      "Loading dark matter...\n",
      "Loading skewers...\n",
      "Setting test set...\n"
     ]
    }
   ],
   "source": [
    "localtime_n = ['2020-12-24 23:42:28']\n",
    "localtime_i = localtime_n[0]\n",
    "localtime = time.strptime(localtime_i, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "# device used to train the model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using device:', torch.cuda.get_device_name(device=device.index))\n",
    "\n",
    "\n",
    "# load dark matter data\n",
    "print('Loading dark matter...')\n",
    "DM_general = load_DM(folder, DM_name)\n",
    "DM_general = DM_general.transpose(0,3,2,1)\n",
    "DM_general = DM_general[[0,3,2,1]]\n",
    "# basic paramters\n",
    "DM_param.pix  = len(DM_general[0])\n",
    "DM_param.len  = 75 # in Mpc/h\n",
    "DM_param.reso = DM_param.len / DM_param.pix # in Mpc/h\n",
    "# test\n",
    "if DM_general.shape[1]<train_insize.min():\n",
    "    raise ValueError('DarkMatter cube size',\n",
    "        DM_general.shape, 'is too small for train size', train_insize, '.')\n",
    "DM_general = torch.tensor(DM_general).float()\n",
    "\n",
    "\n",
    "# load skewers\n",
    "print('Loading skewers...')\n",
    "ske, block = load_skewers(folder, ske_name, train_ousize, DM_param)\n",
    "#ske_FGPA, block = load_skewers(folder, FGPA_name, train_ousize, DM_param)\n",
    "skeFGPA_file = fits.open(folder/FGPA_name)\n",
    "ske_FGPA = skeFGPA_file[0].data\n",
    "skeFGPA_file.close()\n",
    "ske_FGPA = ske_FGPA.transpose(2,1,0)\n",
    "ske_FGPA = load_FGPA(ske_FGPA, train_ousize, DM_param)\n",
    "# basic parameters\n",
    "ske_len = int(ske.shape[-1])\n",
    "\n",
    "\n",
    "# divide the sample to training, validation set, and test set.\n",
    "print('Setting test set...')\n",
    "'''\n",
    "with open(\"id_seperate/id_seperate_%s.txt\"\\\n",
    "          %time.strftime(\"%Y-%m-%d_%H:%M:%S\", localtime), \"r\") as f:\n",
    "    aa = f.readlines()\n",
    "    id_seperate = np.array(list(aa[0][::3])).astype('int')\n",
    "    del aa\n",
    "f.close()\n",
    "'''\n",
    "id_seperate = (np.concatenate((np.ones(36000), np.zeros(360000-36000)))*3).astype(int)\n",
    "np.random.shuffle(id_seperate)\n",
    "\n",
    "test_ske, test_block = load_test(ske, block, id_seperate,\n",
    "                                 train_ousize, test_batch, pre_proc)\n",
    "test_FGPA, test_block = load_test(ske_FGPA, block, id_seperate,\n",
    "                                 train_ousize, test_batch, pre_proc)\n",
    "del id_seperate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalization_outp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-34484a2dc3af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this parameter deviates the PDF of ML F and hydro\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# why so large difference? maybe train on normalized skewers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnormalization_outp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalization_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'normalization_outp' is not defined"
     ]
    }
   ],
   "source": [
    "# this parameter deviates the PDF of ML F and hydro\n",
    "# why so large difference? maybe train on normalized skewers\n",
    "normalization_outp, normalization_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Begin testing...\n",
      "Step [ 100/5760] Loss: 0.5311, Time: 14.5992\n",
      "Step [ 200/5760] Loss: 0.4116, Time: 29.7110\n",
      "Step [ 300/5760] Loss: 0.5083, Time: 44.9756\n",
      "Step [ 400/5760] Loss: 0.4794, Time: 59.6375\n",
      "Step [ 500/5760] Loss: 0.4579, Time: 74.2661\n",
      "Step [ 600/5760] Loss: 0.4573, Time: 89.4825\n",
      "Step [ 700/5760] Loss: 0.4263, Time: 104.1855\n",
      "Step [ 800/5760] Loss: 0.8187, Time: 119.0696\n",
      "Step [ 900/5760] Loss: 0.3824, Time: 133.8021\n",
      "Step [1000/5760] Loss: 0.4776, Time: 148.5945\n",
      "Step [1100/5760] Loss: 0.4278, Time: 163.8051\n",
      "Step [1200/5760] Loss: 0.3739, Time: 178.8925\n",
      "Step [1300/5760] Loss: 0.4636, Time: 194.0164\n",
      "Step [1400/5760] Loss: 0.3488, Time: 209.5528\n",
      "Step [1500/5760] Loss: 0.5367, Time: 224.3768\n",
      "Step [1600/5760] Loss: 0.4038, Time: 239.1475\n",
      "Step [1700/5760] Loss: 0.7081, Time: 253.9317\n",
      "Step [1800/5760] Loss: 0.7611, Time: 268.7659\n",
      "Step [1900/5760] Loss: 0.5453, Time: 283.6090\n",
      "Step [2000/5760] Loss: 0.4230, Time: 298.5796\n",
      "Step [2100/5760] Loss: 0.6926, Time: 313.1705\n",
      "Step [2200/5760] Loss: 0.4441, Time: 328.3379\n",
      "Step [2300/5760] Loss: 0.3971, Time: 342.6880\n",
      "Step [2400/5760] Loss: 0.7383, Time: 357.2438\n",
      "Step [2500/5760] Loss: 0.4120, Time: 372.0440\n",
      "Step [2600/5760] Loss: 0.5673, Time: 386.5578\n",
      "Step [2700/5760] Loss: 0.7731, Time: 401.4296\n",
      "Step [2800/5760] Loss: 0.5956, Time: 416.0340\n",
      "Step [2900/5760] Loss: 0.4785, Time: 431.5092\n",
      "Step [3000/5760] Loss: 0.6927, Time: 446.2050\n",
      "Step [3100/5760] Loss: 0.4678, Time: 460.9293\n",
      "Step [3200/5760] Loss: 0.5829, Time: 476.1141\n",
      "Step [3300/5760] Loss: 0.4227, Time: 491.0320\n",
      "Step [3400/5760] Loss: 0.4265, Time: 506.0050\n",
      "Step [3500/5760] Loss: 0.9506, Time: 520.3647\n",
      "Step [3600/5760] Loss: 0.4973, Time: 534.3752\n",
      "Step [3700/5760] Loss: 0.4732, Time: 548.6217\n",
      "Step [3800/5760] Loss: 0.4363, Time: 562.8162\n",
      "Step [3900/5760] Loss: 0.3719, Time: 576.9421\n",
      "Step [4000/5760] Loss: 0.4733, Time: 591.5603\n",
      "Step [4100/5760] Loss: 0.3813, Time: 605.6192\n",
      "Step [4200/5760] Loss: 0.8585, Time: 620.2085\n",
      "Step [4300/5760] Loss: 0.4415, Time: 634.6461\n",
      "Step [4400/5760] Loss: 0.5498, Time: 649.2335\n",
      "Step [4500/5760] Loss: 0.6276, Time: 663.7117\n",
      "Step [4600/5760] Loss: 0.4393, Time: 678.3164\n",
      "Step [4700/5760] Loss: 0.4162, Time: 692.4950\n",
      "Step [4800/5760] Loss: 0.4490, Time: 706.8266\n",
      "Step [4900/5760] Loss: 0.4586, Time: 721.4340\n",
      "Step [5000/5760] Loss: 0.6296, Time: 736.0508\n",
      "Step [5100/5760] Loss: 0.4029, Time: 750.7737\n",
      "Step [5200/5760] Loss: 0.5014, Time: 765.1576\n",
      "Step [5300/5760] Loss: 0.4089, Time: 779.8499\n",
      "Step [5400/5760] Loss: 0.4063, Time: 794.3411\n",
      "Step [5500/5760] Loss: 0.5678, Time: 808.8501\n",
      "Step [5600/5760] Loss: 0.4499, Time: 823.2627\n",
      "Step [5700/5760] Loss: 0.4266, Time: 838.0161\n",
      "Test Summary: \n",
      "\tTest loss: 0.5283192865809219\n",
      "Restoring test skewers...\n"
     ]
    }
   ],
   "source": [
    "from scipy import optimize\n",
    "def norm_specs(skewers,redshift):\n",
    "    tauevo = 0.001845*(1+redshift)**3.924 #optical depth corresponding to the mean-flux of Faucher-Giguere et al. 2008 \n",
    "    fobs = np.exp(-tauevo)\n",
    "    def fun(a): return np.mean(np.exp(-a*skewers)-fobs)\n",
    "    a = optimize.newton(fun, 1)    \n",
    "    return a\n",
    "rs = 2.0020281392528516 #redshift of the snapshot\n",
    "\n",
    "\n",
    "# load model\n",
    "print('Loading model...')\n",
    "model = get_residual_network().float().to(device)\n",
    "model.load_state_dict(torch.load('params/params_%s.pkl'\\\n",
    "        %time.strftime(\"%Y-%m-%d_%H:%M:%S\", localtime)))\n",
    "'''\n",
    "model.load_state_dict(torch.load('params/HyPhy_%s'\\\n",
    "        %time.strftime(\"%Y-%m-%d_%H:%M:%S\", localtime)))\n",
    "'''\n",
    "\n",
    "\n",
    "# loss\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "\n",
    "# record starr time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# start test\n",
    "print('Begin testing...')\n",
    "test_outp, test_losses = test(test_ske, test_block, DM_general, DM_param,\n",
    "                        test_batch, train_insize, model, criterion, device, start_time)\n",
    "\n",
    "print(\"Test Summary: \")\n",
    "print(\"\\tTest loss: {}\".format(test_losses))\n",
    "\n",
    "# restore test skewers\n",
    "print('Restoring test skewers...')\n",
    "nz = (ske_len/train_ousize[2]).astype('int')\n",
    "test_outp = test_outp.reshape(-1, nz, train_ousize[0],\n",
    "                            train_ousize[1], train_ousize[2])\\\n",
    "                            .transpose(0, 2, 3, 1, 4).reshape(-1, ske_len)\n",
    "test_ske = test_ske.numpy().reshape(-1, nz, train_ousize[0],\n",
    "                            train_ousize[1], train_ousize[2])\\\n",
    "                            .transpose(0, 2, 3, 1, 4).reshape(-1, ske_len)\n",
    "test_FGPA = test_FGPA.numpy().reshape(-1, nz, train_ousize[0],\n",
    "                            train_ousize[1], train_ousize[2])\\\n",
    "                            .transpose(0, 2, 3, 1, 4).reshape(-1, ske_len)\n",
    "\n",
    "tau = np.exp(test_ske)\n",
    "F_hydro = np.exp(-tau)\n",
    "F_sum = F_hydro.sum(axis=1)\n",
    "limit = np.percentile(F_sum, 10)\n",
    "bln = F_sum >= limit\n",
    "tau = tau[bln]\n",
    "normalization = norm_specs(tau,rs) #determine the normalization constant on the whole tau box\n",
    "tau_normed = normalization*tau #normalized optical depth\n",
    "test_ske = np.exp(-normalization*tau) #normalized flux\n",
    "\n",
    "tau = np.exp(test_outp[bln])\n",
    "normalization = norm_specs(tau,rs) #determine the normalization constant on the whole tau box\n",
    "tau_normed = normalization*tau #normalized optical depth\n",
    "test_outp = np.exp(-normalization*tau) #normalized flux\n",
    "\n",
    "tau = np.exp(test_FGPA[bln])\n",
    "normalization = norm_specs(tau,rs) #determine the normalization constant on the whole tau box\n",
    "tau_normed = normalization*tau #normalized optical depth\n",
    "test_FGPA = np.exp(-normalization*tau) #normalized flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting example skewers...\n",
      "[0.87123859 0.87123901 0.87123972]\n",
      "Plotting   1/200, y117z387.png...\n",
      "Plotting   2/200, y083z171.png...\n",
      "Plotting   3/200, y249z282.png...\n",
      "Plotting   4/200, y150z391.png...\n",
      "Plotting   5/200, y166z362.png...\n",
      "Plotting   6/200, y240z115.png...\n",
      "Plotting   7/200, y152z362.png...\n",
      "Plotting   8/200, y041z477.png...\n",
      "Plotting   9/200, y056z543.png...\n",
      "Plotting  10/200, y310z357.png...\n",
      "Plotting  11/200, y390z428.png...\n",
      "Plotting  12/200, y143z472.png...\n",
      "Plotting  13/200, y229z531.png...\n",
      "Plotting  14/200, y512z254.png...\n",
      "Plotting  15/200, y000z235.png...\n",
      "Plotting  16/200, y378z140.png...\n",
      "Plotting  17/200, y045z232.png...\n",
      "Plotting  18/200, y316z153.png...\n",
      "Plotting  19/200, y538z324.png...\n",
      "Plotting  20/200, y256z403.png...\n",
      "Plotting  21/200, y137z404.png...\n",
      "Plotting  22/200, y524z194.png...\n",
      "Plotting  23/200, y170z193.png...\n",
      "Plotting  24/200, y215z387.png...\n",
      "Plotting  25/200, y084z503.png...\n",
      "Plotting  26/200, y232z411.png...\n",
      "Plotting  27/200, y179z113.png...\n",
      "Plotting  28/200, y139z187.png...\n",
      "Plotting  29/200, y410z047.png...\n",
      "Plotting  30/200, y120z340.png...\n",
      "Plotting  31/200, y211z464.png...\n",
      "Plotting  32/200, y146z592.png...\n",
      "Plotting  33/200, y403z095.png...\n",
      "Plotting  34/200, y314z566.png...\n",
      "Plotting  35/200, y095z596.png...\n",
      "Plotting  36/200, y132z387.png...\n",
      "Plotting  37/200, y511z488.png...\n",
      "Plotting  38/200, y232z005.png...\n",
      "Plotting  39/200, y470z303.png...\n",
      "Plotting  40/200, y106z243.png...\n",
      "Plotting  41/200, y021z117.png...\n",
      "Plotting  42/200, y145z436.png...\n",
      "Plotting  43/200, y015z198.png...\n",
      "Plotting  44/200, y458z412.png...\n",
      "Plotting  45/200, y253z581.png...\n",
      "Plotting  46/200, y134z262.png...\n",
      "Plotting  47/200, y069z163.png...\n",
      "Plotting  48/200, y308z272.png...\n",
      "Plotting  49/200, y263z238.png...\n",
      "Plotting  50/200, y119z127.png...\n",
      "Plotting  51/200, y488z544.png...\n",
      "Plotting  52/200, y166z558.png...\n",
      "Plotting  53/200, y409z132.png...\n",
      "Plotting  54/200, y004z419.png...\n",
      "Plotting  55/200, y411z554.png...\n",
      "Plotting  56/200, y324z343.png...\n",
      "Plotting  57/200, y196z550.png...\n",
      "Plotting  58/200, y455z380.png...\n",
      "Plotting  59/200, y388z001.png...\n",
      "Plotting  60/200, y225z425.png...\n",
      "Plotting  61/200, y324z385.png...\n",
      "Plotting  62/200, y020z328.png...\n",
      "Plotting  63/200, y253z413.png...\n",
      "Plotting  64/200, y332z128.png...\n",
      "Plotting  65/200, y297z248.png...\n",
      "Plotting  66/200, y300z259.png...\n",
      "Plotting  67/200, y491z273.png...\n",
      "Plotting  68/200, y472z315.png...\n",
      "Plotting  69/200, y412z537.png...\n",
      "Plotting  70/200, y484z081.png...\n",
      "Plotting  71/200, y032z353.png...\n",
      "Plotting  72/200, y513z588.png...\n",
      "Plotting  73/200, y473z484.png...\n",
      "Plotting 138/200, y054z121.png...\n",
      "Plotting 139/200, y084z347.png...\n",
      "Plotting 140/200, y207z589.png...\n",
      "Plotting 141/200, y467z501.png...\n",
      "Plotting 142/200, y152z513.png...\n",
      "Plotting 143/200, y026z393.png...\n",
      "Plotting 144/200, y242z468.png...\n",
      "Plotting 145/200, y243z400.png...\n",
      "Plotting 146/200, y072z291.png...\n",
      "Plotting 147/200, y335z088.png...\n",
      "Plotting 148/200, y274z507.png...\n",
      "Plotting 149/200, y394z523.png...\n",
      "Plotting 150/200, y501z087.png...\n",
      "Plotting 151/200, y247z285.png...\n",
      "Plotting 152/200, y342z027.png...\n",
      "Plotting 153/200, y524z515.png...\n",
      "Plotting 154/200, y412z187.png...\n",
      "Plotting 155/200, y426z211.png...\n",
      "Plotting 156/200, y450z400.png...\n",
      "Plotting 157/200, y077z364.png...\n",
      "Plotting 158/200, y452z417.png...\n",
      "Plotting 159/200, y432z546.png...\n",
      "Plotting 160/200, y487z000.png...\n",
      "Plotting 161/200, y429z077.png...\n",
      "Plotting 162/200, y317z415.png...\n",
      "Plotting 163/200, y079z533.png...\n",
      "Plotting 164/200, y446z599.png...\n",
      "Plotting 165/200, y207z084.png...\n",
      "Plotting 166/200, y011z458.png...\n",
      "Plotting 167/200, y121z282.png...\n",
      "Plotting 168/200, y463z206.png...\n",
      "Plotting 169/200, y035z497.png...\n",
      "Plotting 170/200, y020z182.png...\n",
      "Plotting 171/200, y141z198.png...\n",
      "Plotting 172/200, y112z107.png...\n",
      "Plotting 173/200, y081z366.png...\n",
      "Plotting 174/200, y536z030.png...\n",
      "Plotting 175/200, y175z316.png...\n",
      "Plotting 176/200, y087z564.png...\n",
      "Plotting 177/200, y533z542.png...\n",
      "Plotting 178/200, y280z296.png...\n",
      "Plotting 179/200, y148z596.png...\n",
      "Plotting 180/200, y161z355.png...\n",
      "Plotting 181/200, y321z451.png...\n",
      "Plotting 182/200, y476z021.png...\n",
      "Plotting 183/200, y436z212.png...\n",
      "Plotting 184/200, y351z559.png...\n",
      "Plotting 185/200, y293z272.png...\n",
      "Plotting 186/200, y231z247.png...\n",
      "Plotting 187/200, y354z535.png...\n",
      "Plotting 188/200, y074z190.png...\n",
      "Plotting 189/200, y476z047.png...\n",
      "Plotting 190/200, y461z292.png...\n",
      "Plotting 191/200, y521z443.png...\n",
      "Plotting 192/200, y385z127.png...\n",
      "Plotting 193/200, y003z021.png...\n",
      "Plotting 194/200, y164z261.png...\n",
      "Plotting 195/200, y339z046.png...\n",
      "Plotting 196/200, y158z146.png...\n",
      "Plotting 197/200, y324z147.png...\n",
      "Plotting 198/200, y102z166.png...\n",
      "Plotting 199/200, y384z513.png...\n",
      "Plotting 200/200, y350z109.png...\n",
      "Measuring accuracy of the rest skewers...\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'fig' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ead383e65d1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     stat_i = test_accuracy(test_block_i, test_outp_i, test_ske_i, test_FGPA_i,\n\u001b[0;32m---> 92\u001b[0;31m                       test_DM_i, F_mean, v_end, folder_outp, bins, plot=False)\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0maccuracy_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrela_err_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstat_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/skewers/skewers_ML/SkeNet_Illustris1_Ver1.0/test.py\u001b[0m in \u001b[0;36mtest_accuracy\u001b[0;34m(test_block_i, test_outp_i, test_ske_i, test_FGPA_i, test_DM_i, F_mean, v_end, folder_outp, bins, plot)\u001b[0m\n\u001b[1;32m    155\u001b[0m                        onePS_FGPA, accuracy_i, rela_err_i])\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstat_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'fig' referenced before assignment"
     ]
    }
   ],
   "source": [
    "'''\n",
    "test_outp = toF_proc(test_outp)\n",
    "test_ske  = toF_proc(test_ske)\n",
    "test_FGPA = toF_proc(test_FGPA)\n",
    "'''\n",
    "test_coord = test_block.reshape(-1, nz, 3)[:, 0, 0:2].T.reshape(2, 1, 1, -1)\n",
    "xcoor = np.arange(train_ousize[0]) - np.arange(train_ousize[0]).mean()\n",
    "ycoor = np.arange(train_ousize[1]) - np.arange(train_ousize[1]).mean()\n",
    "mesh  = np.expand_dims(np.array(np.meshgrid(xcoor, ycoor)), -1)\n",
    "test_block = (test_coord + mesh).transpose(3,2,1,0).reshape(-1, 2).astype(int)\n",
    "del test_coord, xcoor, ycoor, mesh\n",
    "\n",
    "\n",
    "print('Plotting example skewers...')\n",
    "# generate comparison images\n",
    "folder_outp = Path.cwd()/'test_figs'/('%s_x'\\\n",
    "        %time.strftime(\"%Y-%m-%d_%H:%M:%S_FGPA\", localtime))\n",
    "if not os.path.exists(folder_outp):\n",
    "    os.makedirs(folder_outp)\n",
    "\n",
    "\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "import astropy.units as u\n",
    "z = 2.0\n",
    "h= 0.704\n",
    "cosmo = FlatLambdaCDM(H0=100.0*h, Om0=0.2726, Ob0=0.0456)\n",
    "Hz = cosmo.H(z)\n",
    "a = 1.0 / (1.0 + z)\n",
    "v_end  = (a * Hz * 75/h*u.Mpc).to(u.km / u.s).value\n",
    "F_mean = np.array([test_ske.mean(), test_outp.mean(), test_FGPA.mean()])\n",
    "print(F_mean)\n",
    "\n",
    "nrange = min(len(test_ske), 200)\n",
    "test_sp = np.arange(len(test_ske))\n",
    "np.random.seed(99)\n",
    "np.random.shuffle(test_sp)\n",
    "test_sp1 = test_sp[:int(nrange)].astype('int')\n",
    "test_sp2 = test_sp[int(nrange):].astype('int')\n",
    "\n",
    "bins = int(15)\n",
    "accuracy = AverageMeter()\n",
    "rela_err = AverageMeter()\n",
    "accu_arr = np.zeros(shape=(len(test_ske), 2))\n",
    "erro_arr = np.zeros(shape=(len(test_ske), 2))\n",
    "oneDPS   = np.zeros(shape=(4, len(test_ske), bins))\n",
    "\n",
    "\n",
    "# loop\n",
    "import datetime\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "with PdfPages('Example_Skewers.pdf') as pdf:\n",
    "    for i, ii in enumerate(test_sp1):\n",
    "        print('Plotting {:{}d}/{}, y{:03d}z{:03d}.png...'\\\n",
    "                .format((i+1), int(np.log10(nrange)+1), nrange,\n",
    "                        test_block[ii,0], test_block[ii,1]))\n",
    "\n",
    "        test_block_i = test_block[ii]\n",
    "        test_outp_i = test_outp[ii]\n",
    "        test_ske_i = test_ske[ii]\n",
    "        test_FGPA_i = test_FGPA[ii]\n",
    "        test_DM_i = DM_general[0, test_block_i[0], test_block_i[1], :].numpy()\n",
    "\n",
    "        stat_i, fig = test_accuracy(test_block_i, test_outp_i, test_ske_i, test_FGPA_i,\n",
    "                          test_DM_i, F_mean, v_end, folder_outp, bins, plot=True)\n",
    "        accuracy_i, rela_err_i = stat_i[[4,5]]\n",
    "        accuracy.update(accuracy_i, 1)\n",
    "        rela_err.update(rela_err_i, 1)\n",
    "        accu_arr[ii] = accuracy_i\n",
    "        erro_arr[ii] = rela_err_i\n",
    "        oneDPS[:,ii] = stat_i[0], stat_i[1], stat_i[2], stat_i[3]\n",
    "    \n",
    "        pdf.savefig(fig)\n",
    "        \n",
    "    d = pdf.infodict()\n",
    "    d['Title'] = 'Example Skewers'\n",
    "    d['Author'] = 'Yi Kang'\n",
    "    #d['Subject'] = 'How to create a multipage pdf file and set its metadata'\n",
    "    #d['Keywords'] = 'PdfPages multipage keywords author title subject'\n",
    "    d['CreationDate'] = datetime.datetime.today()\n",
    "    d['ModDate'] = datetime.datetime.today()\n",
    "    \n",
    "print('Measuring accuracy of the rest skewers...')\n",
    "for i, ii in enumerate(test_sp2):\n",
    "\n",
    "    test_block_i = test_block[ii]\n",
    "    test_outp_i = test_outp[ii]\n",
    "    test_ske_i = test_ske[ii]\n",
    "    test_FGPA_i = test_FGPA[ii]\n",
    "    test_DM_i = DM_general[0, test_block_i[0], test_block_i[1], :].numpy()\n",
    "\n",
    "    stat_i = test_accuracy(test_block_i, test_outp_i, test_ske_i, test_FGPA_i,\n",
    "                      test_DM_i, F_mean, v_end, folder_outp, bins, plot=False)\n",
    "    accuracy_i, rela_err_i = stat_i[[4,5]]\n",
    "    accuracy.update(accuracy_i, 1)\n",
    "    rela_err.update(rela_err_i, 1)\n",
    "    accu_arr[ii] = accuracy_i\n",
    "    erro_arr[ii] = rela_err_i\n",
    "    oneDPS[:,ii] = stat_i[0], stat_i[1], stat_i[2], stat_i[3]\n",
    "\n",
    "\n",
    "print('Plotting average 1DPS and PDF...')\n",
    "oneDPS_backup = oneDPS\n",
    "oneDPS = oneDPS.mean(axis=1)\n",
    "oneDPS = oneDPS[~np.isnan(oneDPS)].reshape(4,-1)\n",
    "bln = oneDPS[0]<0.1\n",
    "accuracy_gen = np.abs((oneDPS[1]-oneDPS[2])/oneDPS[2])[bln].mean()\n",
    "rela_err_gen = np.abs((oneDPS[1]-oneDPS[2])/oneDPS[2])[bln].std()\n",
    "accuracy_FGPA = np.abs((oneDPS[3]-oneDPS[2])/oneDPS[2])[bln].mean()\n",
    "rela_err_FGPA = np.abs((oneDPS[3]-oneDPS[2])/oneDPS[2])[bln].std()\n",
    "\n",
    "outp_hist, F_hist = np.histogram(test_outp, bins=np.arange(0,1.05,0.05))\n",
    "test_hist, F_hist = np.histogram(test_ske,  bins=np.arange(0,1.05,0.05))\n",
    "FGPA_hist, F_hist = np.histogram(test_FGPA, bins=np.arange(0,1.05,0.05))\n",
    "outp_hist = np.append(outp_hist, outp_hist[-1]) / len(test_ske)\n",
    "test_hist = np.append(test_hist, test_hist[-1]) / len(test_ske)\n",
    "FGPA_hist = np.append(FGPA_hist, FGPA_hist[-1]) / len(test_ske)\n",
    "bln = (F_hist>=0.1) & (F_hist<0.9)\n",
    "accuracy_hist = np.abs((outp_hist-test_hist)/test_hist)[bln].mean()\n",
    "rela_err_hist = np.abs((outp_hist-test_hist)/test_hist)[bln].std()\n",
    "m_hist_FGPA = np.abs((FGPA_hist-test_hist)/test_hist)[bln].mean()\n",
    "s_hist_FGPA = np.abs((FGPA_hist-test_hist)/test_hist)[bln].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(2,2,figsize=(15,11))\n",
    "\n",
    "p0 = axes[0,0].hist(accu_arr[:,0], label='ML', bins=np.arange(0, 1.7, 0.1))\n",
    "axes[0,0].set_xlim(-0.1, 1.8)\n",
    "axes[0,0].set_ylim(axes[0,0].get_ylim())\n",
    "p1 = axes[0,0].vlines(x=np.median(accu_arr[:,0]), ymin=0, ymax=9999, linestyle='--')\n",
    "p9 = axes[0,0].hist(accu_arr[:,1], label='FGPA', color='tab:green', bins=np.arange(0, 1.7, 0.1), alpha=0.5)\n",
    "axes[0,0].set_xlabel('accuracy $m$', fontsize=14)\n",
    "axes[0,0].set_title('pdf of $m$', fontsize=14)\n",
    "axes[0,0].tick_params(labelsize=12, direction='in')\n",
    "customs = [p1, \n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                  markerfacecolor='k', markersize=5),\n",
    "          p9]\n",
    "axes[0,0].legend(customs, ['median $m=%.4f$'%np.median(accu_arr),\n",
    "                        '$N=%d$'%len(accu_arr)], fontsize=12, loc=1)\n",
    "\n",
    "axes[0,1].hist(erro_arr[0], color='grey', bins=np.arange(0, 1.7, 0.1))\n",
    "axes[0,1].set_xlim(-0.1, 1.8)\n",
    "axes[0,1].set_ylim(axes[0,1].get_ylim())\n",
    "p2 = axes[0,1].vlines(x=erro_arr.mean(), ymin=0, ymax=9999, linestyle='--')\n",
    "axes[0,1].set_xlabel('error $s$', fontsize=14)\n",
    "axes[0,1].set_title('pdf of $s$', fontsize=14)\n",
    "axes[0,1].tick_params(labelsize=12, direction='in')\n",
    "customs = [p2, \n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                  markerfacecolor='k', markersize=5)]\n",
    "axes[0,1].legend(customs, ['average $s=%.4f$'%erro_arr.mean(),\n",
    "                        '$N=%d$'%len(erro_arr)], fontsize=12, loc=1)\n",
    "\n",
    "p3, = axes[1,0].plot(oneDPS[0], oneDPS[1], label='ML')\n",
    "p4, = axes[1,0].plot(oneDPS[0], oneDPS[2], label='Hydro', alpha=0.5)\n",
    "p7, = axes[1,0].plot(oneDPS[0], oneDPS[3], label='FGPA', alpha=0.5)\n",
    "axes[1,0].set_xlabel(r'$k\\ (\\mathrm{s/km})$', fontsize=14)\n",
    "axes[1,0].set_ylabel(r'$kP_\\mathrm{1D}/\\pi$', fontsize=14)\n",
    "axes[1,0].set_xscale('log')\n",
    "axes[1,0].set_yscale('log')\n",
    "axes[1,0].set_ylim(axes[1,0].get_ylim())\n",
    "axes[1,0].vlines(x=0.1, ymin=1e-8, ymax=1e8)\n",
    "axes[1,0].set_title('Average 1DPS', fontsize=14)\n",
    "axes[1,0].tick_params(labelsize=12, direction='in', which='both')\n",
    "customs = [p3,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p7,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p4]\n",
    "axes[1,0].legend(customs, [p3.get_label(), '$m=%.3f$'%accuracy_gen, '$s=%.3f$'%rela_err_gen, \n",
    "                    p7.get_label(),'$m=%.3f$'%accuracy_FGPA, '$s=%.3f$'%rela_err_FGPA,\n",
    "                    p4.get_label()], fontsize=12)\n",
    "\n",
    "p5, = axes[1,1].step(F_hist, outp_hist, where='post', label='ML')\n",
    "p6, = axes[1,1].step(F_hist, test_hist, where='post', label='Hydro', alpha=0.5)\n",
    "p8, = axes[1,1].step(F_hist, FGPA_hist, where='post', label='FGPA', alpha=0.5)\n",
    "axes[1,1].set_xlabel(r'$F$', fontsize=18)\n",
    "axes[1,1].set_ylabel(r'Counts', fontsize=18)\n",
    "axes[1,1].set_xlim([0, 1])\n",
    "axes[1,1].set_ylim(bottom=0)\n",
    "axes[1,1].vlines(x=0.1, ymin=0, ymax=6000)\n",
    "axes[1,1].vlines(x=0.9, ymin=0, ymax=6000)\n",
    "axes[1,1].set_title('Average PDF of $F$', fontsize=14)\n",
    "axes[1,1].tick_params(labelsize=12, direction='in')\n",
    "customs = [p5,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p8,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p6]\n",
    "axes[1,1].legend(customs, [p5.get_label(), '$m=%.3f$'%accuracy_hist, '$s=%.3f$'%rela_err_hist,\n",
    "                    p8.get_label(),'$m=%.3f$'%m_hist_FGPA, '$s=%.3f$'%s_hist_FGPA,\n",
    "                    p6.get_label()], fontsize=12)\n",
    "\n",
    "#plt.savefig(folder_outp / ('average.png'), dpi=300, bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = 4\n",
    "vaxis = np.arange(ske_len)/ske_len * v_end\n",
    "order = np.random.randint(len(test_ske), size=examples)\n",
    "\n",
    "fig, axes = plt.subplots(examples,1,figsize=(12,examples*2.4))\n",
    "\n",
    "for i in range(examples):\n",
    "    axes[i].plot(vaxis, test_outp[order[i]], label='ML',  alpha=0.7)\n",
    "    axes[i].plot(vaxis, test_FGPA[order[i]], label='FGPA', color='tab:green', alpha=0.5)\n",
    "    axes[i].plot(vaxis, test_ske[order[i]], label='Hydro', color='tab:orange', alpha=0.7)\n",
    "    axes[i].set_xlim([0, max(vaxis)])\n",
    "    axes[i].set_ylim([0,1])\n",
    "    axes[i].set_yticklabels([0.0, 0.2, 0.4, 0.6, 0.8])\n",
    "    axes[i].set_ylabel(r'$F$', fontsize=18, labelpad=0.5)\n",
    "    if i != int(examples-1):\n",
    "        axes[i].set_xticklabels([])\n",
    "axes[0].set_yticklabels([0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "axes[-1].set_xlabel(r'$v$ (km/s)', fontsize=18, labelpad=0.5)\n",
    "axes[-1].legend(fontsize=18, bbox_to_anchor=(1.25,2.75))\n",
    "plt.subplots_adjust(hspace=0)\n",
    "#plt.savefig(folder_outp / ('examples.png'), dpi=600, bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_deviation = (oneDPS[2] - oneDPS[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneDPS_backup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneDPS_deviation = (oneDPS_backup[2] - oneDPS_backup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bln = oneDPS_deviation[:,0] > final_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = np.exp(test_ske)\n",
    "F_hydro = np.exp(-tau)\n",
    "F_sum = F_hydro.sum(axis=1)\n",
    "limit = np.percentile(F_sum, 20)\n",
    "bln = F_sum >= limit\n",
    "tau = tau[bln]\n",
    "normalization = norm_specs(tau,rs) #determine the normalization constant on the whole tau box\n",
    "tau_normed = normalization*tau #normalized optical depth\n",
    "test_ske = np.exp(-normalization*tau) #normalized flux\n",
    "\n",
    "tau = np.exp(test_outp[bln])\n",
    "normalization = norm_specs(tau,rs) #determine the normalization constant on the whole tau box\n",
    "tau_normed = normalization*tau #normalized optical depth\n",
    "test_outp = np.exp(-normalization*tau) #normalized flux\n",
    "\n",
    "tau = np.exp(test_FGPA[bln])\n",
    "normalization = norm_specs(tau,rs) #determine the normalization constant on the whole tau box\n",
    "tau_normed = normalization*tau #normalized optical depth\n",
    "test_FGPA = np.exp(-normalization*tau) #normalized flux\n",
    "'''\n",
    "test_outp = toF_proc(test_outp)\n",
    "test_ske  = toF_proc(test_ske)\n",
    "test_FGPA = toF_proc(test_FGPA)\n",
    "'''\n",
    "test_coord = test_block.reshape(-1, nz, 3)[:, 0, 0:2].T.reshape(2, 1, 1, -1)\n",
    "xcoor = np.arange(train_ousize[0]) - np.arange(train_ousize[0]).mean()\n",
    "ycoor = np.arange(train_ousize[1]) - np.arange(train_ousize[1]).mean()\n",
    "mesh  = np.expand_dims(np.array(np.meshgrid(xcoor, ycoor)), -1)\n",
    "test_block = (test_coord + mesh).transpose(3,2,1,0).reshape(-1, 2).astype(int)\n",
    "del test_coord, xcoor, ycoor, mesh\n",
    "\n",
    "\n",
    "print('Plotting example skewers...')\n",
    "# generate comparison images\n",
    "folder_outp = Path.cwd()/'test_figs'/('%s_x'\\\n",
    "        %time.strftime(\"%Y-%m-%d_%H:%M:%S_FGPA\", localtime))\n",
    "if not os.path.exists(folder_outp):\n",
    "    os.makedirs(folder_outp)\n",
    "\n",
    "\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "import astropy.units as u\n",
    "z = 2.0\n",
    "h= 0.704\n",
    "cosmo = FlatLambdaCDM(H0=100.0*h, Om0=0.2726, Ob0=0.0456)\n",
    "Hz = cosmo.H(z)\n",
    "a = 1.0 / (1.0 + z)\n",
    "v_end  = (a * Hz * 75/h*u.Mpc).to(u.km / u.s).value\n",
    "F_mean = np.array([test_ske.mean(), test_outp.mean(), test_FGPA.mean()])\n",
    "print(F_mean)\n",
    "\n",
    "nrange = min(len(test_ske), 50)\n",
    "test_sp = np.arange(len(test_ske))\n",
    "np.random.seed(99)\n",
    "np.random.shuffle(test_sp)\n",
    "test_sp1 = test_sp[:int(nrange)].astype('int')\n",
    "test_sp2 = test_sp[int(nrange):].astype('int')\n",
    "\n",
    "bins = int(15)\n",
    "accuracy = AverageMeter()\n",
    "rela_err = AverageMeter()\n",
    "accu_arr = np.zeros(shape=(len(test_ske), 2))\n",
    "erro_arr = np.zeros(shape=(len(test_ske), 2))\n",
    "oneDPS   = np.zeros(shape=(4, len(test_ske), bins))\n",
    "\n",
    "\n",
    "# loop\n",
    "for i, ii in enumerate(test_sp1):\n",
    "    print('Plotting {:{}d}/{}, y{:03d}z{:03d}.png...'\\\n",
    "            .format((i+1), int(np.log10(nrange)+1), nrange,\n",
    "                    test_block[ii,0], test_block[ii,1]))\n",
    "\n",
    "    test_block_i = test_block[ii]\n",
    "    test_outp_i = test_outp[ii]\n",
    "    test_ske_i = test_ske[ii]\n",
    "    test_FGPA_i = test_FGPA[ii]\n",
    "    test_DM_i = DM_general[0, test_block_i[0], test_block_i[1], :].numpy()\n",
    "\n",
    "    stat_i = test_accuracy(test_block_i, test_outp_i, test_ske_i, test_FGPA_i,\n",
    "                      test_DM_i, F_mean, v_end, folder_outp, bins, plot=True)\n",
    "    accuracy_i, rela_err_i = stat_i[[4,5]]\n",
    "    accuracy.update(accuracy_i, 1)\n",
    "    rela_err.update(rela_err_i, 1)\n",
    "    accu_arr[ii] = accuracy_i\n",
    "    erro_arr[ii] = rela_err_i\n",
    "    oneDPS[:,ii] = stat_i[0], stat_i[1], stat_i[2], stat_i[3]\n",
    "\n",
    "print('Measuring accuracy of the rest skewers...')\n",
    "for i, ii in enumerate(test_sp2):\n",
    "\n",
    "    test_block_i = test_block[ii]\n",
    "    test_outp_i = test_outp[ii]\n",
    "    test_ske_i = test_ske[ii]\n",
    "    test_FGPA_i = test_FGPA[ii]\n",
    "    test_DM_i = DM_general[0, test_block_i[0], test_block_i[1], :].numpy()\n",
    "\n",
    "    stat_i = test_accuracy(test_block_i, test_outp_i, test_ske_i, test_FGPA_i,\n",
    "                      test_DM_i, F_mean, v_end, folder_outp, bins, plot=False)\n",
    "    accuracy_i, rela_err_i = stat_i[[4,5]]\n",
    "    accuracy.update(accuracy_i, 1)\n",
    "    rela_err.update(rela_err_i, 1)\n",
    "    accu_arr[ii] = accuracy_i\n",
    "    erro_arr[ii] = rela_err_i\n",
    "    oneDPS[:,ii] = stat_i[0], stat_i[1], stat_i[2], stat_i[3]\n",
    "\n",
    "\n",
    "print('Plotting average 1DPS and PDF...')\n",
    "oneDPS_backup = oneDPS\n",
    "oneDPS = oneDPS.mean(axis=1)\n",
    "oneDPS = oneDPS[~np.isnan(oneDPS)].reshape(4,-1)\n",
    "bln = oneDPS[0]<0.1\n",
    "accuracy_gen = np.abs((oneDPS[1]-oneDPS[2])/oneDPS[2])[bln].mean()\n",
    "rela_err_gen = np.abs((oneDPS[1]-oneDPS[2])/oneDPS[2])[bln].std()\n",
    "accuracy_FGPA = np.abs((oneDPS[3]-oneDPS[2])/oneDPS[2])[bln].mean()\n",
    "rela_err_FGPA = np.abs((oneDPS[3]-oneDPS[2])/oneDPS[2])[bln].std()\n",
    "\n",
    "outp_hist, F_hist = np.histogram(test_outp, bins=np.arange(0,1.05,0.05))\n",
    "test_hist, F_hist = np.histogram(test_ske,  bins=np.arange(0,1.05,0.05))\n",
    "FGPA_hist, F_hist = np.histogram(test_FGPA, bins=np.arange(0,1.05,0.05))\n",
    "outp_hist = np.append(outp_hist, outp_hist[-1]) / len(test_ske)\n",
    "test_hist = np.append(test_hist, test_hist[-1]) / len(test_ske)\n",
    "FGPA_hist = np.append(FGPA_hist, FGPA_hist[-1]) / len(test_ske)\n",
    "bln = (F_hist>=0.1) & (F_hist<0.9)\n",
    "accuracy_hist = np.abs((outp_hist-test_hist)/test_hist)[bln].mean()\n",
    "rela_err_hist = np.abs((outp_hist-test_hist)/test_hist)[bln].std()\n",
    "m_hist_FGPA = np.abs((FGPA_hist-test_hist)/test_hist)[bln].mean()\n",
    "s_hist_FGPA = np.abs((FGPA_hist-test_hist)/test_hist)[bln].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(2,2,figsize=(15,11))\n",
    "\n",
    "p0 = axes[0,0].hist(accu_arr[:,0], label='ML', bins=np.arange(0, 1.7, 0.1))\n",
    "axes[0,0].set_xlim(-0.1, 1.8)\n",
    "axes[0,0].set_ylim(axes[0,0].get_ylim())\n",
    "p1 = axes[0,0].vlines(x=np.median(accu_arr[:,0]), ymin=0, ymax=9999, linestyle='--')\n",
    "p9 = axes[0,0].hist(accu_arr[:,1], label='FGPA', color='tab:green', bins=np.arange(0, 1.7, 0.1), alpha=0.5)\n",
    "axes[0,0].set_xlabel('accuracy $m$', fontsize=14)\n",
    "axes[0,0].set_title('pdf of $m$', fontsize=14)\n",
    "axes[0,0].tick_params(labelsize=12, direction='in')\n",
    "customs = [p1, \n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                  markerfacecolor='k', markersize=5),\n",
    "          p9]\n",
    "axes[0,0].legend(customs, ['median $m=%.4f$'%np.median(accu_arr[:,0]),\n",
    "                        '$N=%d$'%len(accu_arr)], fontsize=12, loc=1)\n",
    "\n",
    "axes[0,1].hist(erro_arr[:,0], color='grey', bins=np.arange(0, 1.7, 0.1))\n",
    "axes[0,1].set_xlim(-0.1, 1.8)\n",
    "axes[0,1].set_ylim(axes[0,1].get_ylim())\n",
    "p2 = axes[0,1].vlines(x=np.median(erro_arr[:,0]), ymin=0, ymax=9999, linestyle='--')\n",
    "axes[0,1].set_xlabel('error $s$', fontsize=14)\n",
    "axes[0,1].set_title('pdf of $s$', fontsize=14)\n",
    "axes[0,1].tick_params(labelsize=12, direction='in')\n",
    "customs = [p2, \n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                  markerfacecolor='k', markersize=5)]\n",
    "axes[0,1].legend(customs, ['median $s=%.4f$'%np.median(erro_arr[:,0]),\n",
    "                        '$N=%d$'%len(erro_arr)], fontsize=12, loc=1)\n",
    "\n",
    "p3, = axes[1,0].plot(oneDPS[0], oneDPS[1], label='ML')\n",
    "p4, = axes[1,0].plot(oneDPS[0], oneDPS[2], label='Hydro', alpha=0.5)\n",
    "p7, = axes[1,0].plot(oneDPS[0], oneDPS[3], label='FGPA', alpha=0.5)\n",
    "axes[1,0].set_xlabel(r'$k\\ (\\mathrm{s/km})$', fontsize=14)\n",
    "axes[1,0].set_ylabel(r'$kP_\\mathrm{1D}/\\pi$', fontsize=14)\n",
    "axes[1,0].set_xscale('log')\n",
    "axes[1,0].set_yscale('log')\n",
    "axes[1,0].set_ylim(axes[1,0].get_ylim())\n",
    "axes[1,0].vlines(x=0.1, ymin=1e-8, ymax=1e8)\n",
    "axes[1,0].set_title('Average 1DPS', fontsize=14)\n",
    "axes[1,0].tick_params(labelsize=12, direction='in', which='both')\n",
    "customs = [p3,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p7,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p4]\n",
    "axes[1,0].legend(customs, [p3.get_label(), '$m=%.3f$'%accuracy_gen, '$s=%.3f$'%rela_err_gen, \n",
    "                    p7.get_label(),'$m=%.3f$'%accuracy_FGPA, '$s=%.3f$'%rela_err_FGPA,\n",
    "                    p4.get_label()], fontsize=12)\n",
    "\n",
    "p5, = axes[1,1].step(F_hist, outp_hist, where='post', label='ML')\n",
    "p6, = axes[1,1].step(F_hist, test_hist, where='post', label='Hydro', alpha=0.5)\n",
    "p8, = axes[1,1].step(F_hist, FGPA_hist, where='post', label='FGPA', alpha=0.5)\n",
    "axes[1,1].set_xlabel(r'$F$', fontsize=18)\n",
    "axes[1,1].set_ylabel(r'Counts', fontsize=18)\n",
    "axes[1,1].set_xlim([0, 1])\n",
    "axes[1,1].set_ylim(bottom=0)\n",
    "axes[1,1].vlines(x=0.1, ymin=0, ymax=6000)\n",
    "axes[1,1].vlines(x=0.9, ymin=0, ymax=6000)\n",
    "axes[1,1].set_title('Average PDF of $F$', fontsize=14)\n",
    "axes[1,1].tick_params(labelsize=12, direction='in')\n",
    "customs = [p5,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p8,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p6]\n",
    "axes[1,1].legend(customs, [p5.get_label(), '$m=%.3f$'%accuracy_hist, '$s=%.3f$'%rela_err_hist,\n",
    "                    p8.get_label(),'$m=%.3f$'%m_hist_FGPA, '$s=%.3f$'%s_hist_FGPA,\n",
    "                    p6.get_label()], fontsize=12)\n",
    "\n",
    "#plt.savefig(folder_outp / ('average.png'), dpi=300, bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "def norm_specs(skewers,redshift):\n",
    "    tauevo = 0.001845*(1+redshift)**3.924 #optical depth corresponding to the mean-flux of Faucher-Giguere et al. 2008 \n",
    "    fobs = np.exp(-tauevo)\n",
    "    def fun(a): return np.mean(np.exp(-a*skewers)-fobs)\n",
    "    a = optimize.newton(fun, 1)    \n",
    "    return a\n",
    "rs = 2.0020281392528516 #redshift of the snapshot\n",
    "\n",
    "\n",
    "# load model\n",
    "print('Loading model...')\n",
    "model = get_residual_network().float().to(device)\n",
    "model.load_state_dict(torch.load('params/params_%s.pkl'\\\n",
    "        %time.strftime(\"%Y-%m-%d_%H:%M:%S\", localtime)))\n",
    "'''\n",
    "model.load_state_dict(torch.load('params/HyPhy_%s'\\\n",
    "        %time.strftime(\"%Y-%m-%d_%H:%M:%S\", localtime)))\n",
    "'''\n",
    "\n",
    "\n",
    "# loss\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "\n",
    "# record starr time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# start test\n",
    "print('Begin testing...')\n",
    "test_outp, test_losses = test(test_ske, test_block, DM_general, DM_param,\n",
    "                        test_batch, train_insize, model, criterion, device, start_time)\n",
    "\n",
    "print(\"Test Summary: \")\n",
    "print(\"\\tTest loss: {}\".format(test_losses))\n",
    "\n",
    "# restore test skewers\n",
    "print('Restoring test skewers...')\n",
    "nz = (ske_len/train_ousize[2]).astype('int')\n",
    "test_outp = test_outp.reshape(-1, nz, train_ousize[0],\n",
    "                            train_ousize[1], train_ousize[2])\\\n",
    "                            .transpose(0, 2, 3, 1, 4).reshape(-1, ske_len)\n",
    "test_ske = test_ske.numpy().reshape(-1, nz, train_ousize[0],\n",
    "                            train_ousize[1], train_ousize[2])\\\n",
    "                            .transpose(0, 2, 3, 1, 4).reshape(-1, ske_len)\n",
    "test_FGPA = test_FGPA.numpy().reshape(-1, nz, train_ousize[0],\n",
    "                            train_ousize[1], train_ousize[2])\\\n",
    "                            .transpose(0, 2, 3, 1, 4).reshape(-1, ske_len)\n",
    "\n",
    "test_outp = toF_proc(test_outp)\n",
    "test_ske  = toF_proc(test_ske)\n",
    "test_FGPA = toF_proc(test_FGPA)\n",
    "\n",
    "test_coord = test_block.reshape(-1, nz, 3)[:, 0, 0:2].T.reshape(2, 1, 1, -1)\n",
    "xcoor = np.arange(train_ousize[0]) - np.arange(train_ousize[0]).mean()\n",
    "ycoor = np.arange(train_ousize[1]) - np.arange(train_ousize[1]).mean()\n",
    "mesh  = np.expand_dims(np.array(np.meshgrid(xcoor, ycoor)), -1)\n",
    "test_block = (test_coord + mesh).transpose(3,2,1,0).reshape(-1, 2).astype(int)\n",
    "del test_coord, xcoor, ycoor, mesh\n",
    "\n",
    "\n",
    "print('Plotting example skewers...')\n",
    "# generate comparison images\n",
    "folder_outp = Path.cwd()/'test_figs'/('%s_x'\\\n",
    "        %time.strftime(\"%Y-%m-%d_%H:%M:%S_FGPA\", localtime))\n",
    "if not os.path.exists(folder_outp):\n",
    "    os.makedirs(folder_outp)\n",
    "\n",
    "\n",
    "from astropy.cosmology import FlatLambdaCDM\n",
    "import astropy.units as u\n",
    "z = 2.0\n",
    "h= 0.704\n",
    "cosmo = FlatLambdaCDM(H0=100.0*h, Om0=0.2726, Ob0=0.0456)\n",
    "Hz = cosmo.H(z)\n",
    "a = 1.0 / (1.0 + z)\n",
    "v_end  = (a * Hz * 75/h*u.Mpc).to(u.km / u.s).value\n",
    "F_mean = np.array([test_ske.mean(), test_outp.mean(), test_FGPA.mean()])\n",
    "print(F_mean)\n",
    "\n",
    "nrange = min(len(test_ske), 50)\n",
    "test_sp = np.arange(len(test_ske))\n",
    "np.random.seed(99)\n",
    "np.random.shuffle(test_sp)\n",
    "test_sp1 = test_sp[:int(nrange)].astype('int')\n",
    "test_sp2 = test_sp[int(nrange):].astype('int')\n",
    "\n",
    "bins = int(15)\n",
    "accuracy = AverageMeter()\n",
    "rela_err = AverageMeter()\n",
    "accu_arr = np.zeros(len(test_ske))\n",
    "erro_arr = np.zeros(len(test_ske))\n",
    "oneDPS   = np.zeros(shape=(4, len(test_ske), bins))\n",
    "\n",
    "\n",
    "# loop\n",
    "for i, ii in enumerate(test_sp1):\n",
    "    print('Plotting {:{}d}/{}, y{:03d}z{:03d}.png...'\\\n",
    "            .format((i+1), int(np.log10(nrange)+1), nrange,\n",
    "                    test_block[ii,0], test_block[ii,1]))\n",
    "\n",
    "    test_block_i = test_block[ii]\n",
    "    test_outp_i = test_outp[ii]\n",
    "    test_ske_i = test_ske[ii]\n",
    "    test_FGPA_i = test_FGPA[ii]\n",
    "    test_DM_i = DM_general[0, test_block_i[0], test_block_i[1], :].numpy()\n",
    "\n",
    "    stat_i = test_plot(test_block_i, test_outp_i, test_ske_i, test_FGPA_i,\n",
    "                      test_DM_i, F_mean, v_end, folder_outp, bins)\n",
    "    accuracy_i, rela_err_i = stat_i[[4,5]]\n",
    "    accuracy.update(accuracy_i, 1)\n",
    "    rela_err.update(rela_err_i, 1)\n",
    "    accu_arr[ii] = accuracy_i\n",
    "    erro_arr[ii] = rela_err_i\n",
    "    oneDPS[:,ii] = stat_i[0], stat_i[1], stat_i[2], stat_i[3]\n",
    "\n",
    "print('Measuring accuracy of the left skewers...')\n",
    "for i, ii in enumerate(test_sp2):\n",
    "\n",
    "    test_block_i = test_block[ii]\n",
    "    test_outp_i = test_outp[ii]\n",
    "    test_ske_i = test_ske[ii]\n",
    "    test_FGPA_i = test_FGPA[ii]\n",
    "    test_DM_i = DM_general[0, test_block_i[0], test_block_i[1], :].numpy()\n",
    "\n",
    "    stat_i = test_accuracy(test_block_i, test_outp_i, test_ske_i, test_FGPA_i,\n",
    "                          F_mean, v_end, folder_outp, bins)\n",
    "    accuracy_i, rela_err_i = stat_i[[4,5]]\n",
    "    accuracy.update(accuracy_i, 1)\n",
    "    rela_err.update(rela_err_i, 1)\n",
    "    accu_arr[ii] = accuracy_i\n",
    "    erro_arr[ii] = rela_err_i\n",
    "    oneDPS[:,ii] = stat_i[0], stat_i[1], stat_i[2], stat_i[3]\n",
    "\n",
    "\n",
    "print('Plotting average 1DPS and PDF...')\n",
    "#oneDPS_backup = oneDPS\n",
    "oneDPS = oneDPS.mean(axis=1)\n",
    "oneDPS = oneDPS[~np.isnan(oneDPS)].reshape(4,-1)\n",
    "bln = oneDPS[0]<0.1\n",
    "accuracy_gen = np.abs((oneDPS[1]-oneDPS[2])/oneDPS[2])[bln].mean()\n",
    "rela_err_gen = np.abs((oneDPS[1]-oneDPS[2])/oneDPS[2])[bln].std()\n",
    "accuracy_FGPA = np.abs((oneDPS[3]-oneDPS[2])/oneDPS[2])[bln].mean()\n",
    "rela_err_FGPA = np.abs((oneDPS[3]-oneDPS[2])/oneDPS[2])[bln].std()\n",
    "\n",
    "outp_hist, F_hist = np.histogram(test_outp, bins=np.arange(0,1.05,0.05))\n",
    "test_hist, F_hist = np.histogram(test_ske,  bins=np.arange(0,1.05,0.05))\n",
    "FGPA_hist, F_hist = np.histogram(test_FGPA, bins=np.arange(0,1.05,0.05))\n",
    "outp_hist = np.append(outp_hist, outp_hist[-1]) / len(test_ske)\n",
    "test_hist = np.append(test_hist, test_hist[-1]) / len(test_ske)\n",
    "FGPA_hist = np.append(FGPA_hist, FGPA_hist[-1]) / len(test_ske)\n",
    "bln = (F_hist>=0.1) & (F_hist<0.9)\n",
    "accuracy_hist = np.abs((outp_hist-test_hist)/test_hist)[bln].mean()\n",
    "rela_err_hist = np.abs((outp_hist-test_hist)/test_hist)[bln].std()\n",
    "m_hist_FGPA = np.abs((FGPA_hist-test_hist)/test_hist)[bln].mean()\n",
    "s_hist_FGPA = np.abs((FGPA_hist-test_hist)/test_hist)[bln].std()\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2,2,figsize=(15,11))\n",
    "\n",
    "p0=axes[0,0].hist(accu_arr, color='grey', bins=np.arange(0, 1.7, 0.1))\n",
    "axes[0,0].set_xlim(-0.1, 1.8)\n",
    "axes[0,0].set_ylim(axes[0,0].get_ylim())\n",
    "p1 = axes[0,0].vlines(x=accu_arr.mean(), ymin=0, ymax=9999, linestyle='--')\n",
    "axes[0,0].set_xlabel('accuracy $m$', fontsize=14)\n",
    "axes[0,0].set_title('pdf of $m$', fontsize=14)\n",
    "axes[0,0].tick_params(labelsize=12, direction='in')\n",
    "customs = [p1, \n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                  markerfacecolor='k', markersize=5)]\n",
    "axes[0,0].legend(customs, ['average $m=%.4f$'%accu_arr.mean(),\n",
    "                        '$N=%d$'%len(accu_arr)], fontsize=12, loc=1)\n",
    "\n",
    "axes[0,1].hist(erro_arr, color='grey', bins=np.arange(0, 1.7, 0.1))\n",
    "axes[0,1].set_xlim(-0.1, 1.8)\n",
    "axes[0,1].set_ylim(axes[0,1].get_ylim())\n",
    "p2 = axes[0,1].vlines(x=erro_arr.mean(), ymin=0, ymax=9999, linestyle='--')\n",
    "axes[0,1].set_xlabel('error $s$', fontsize=14)\n",
    "axes[0,1].set_title('pdf of $s$', fontsize=14)\n",
    "axes[0,1].tick_params(labelsize=12, direction='in')\n",
    "customs = [p2, \n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                  markerfacecolor='k', markersize=5)]\n",
    "axes[0,1].legend(customs, ['average $s=%.4f$'%erro_arr.mean(),\n",
    "                        '$N=%d$'%len(erro_arr)], fontsize=12, loc=1)\n",
    "\n",
    "p3, = axes[1,0].plot(oneDPS[0], oneDPS[1], label='Predicted')\n",
    "p4, = axes[1,0].plot(oneDPS[0], oneDPS[2], label='Real', alpha=0.5)\n",
    "p7, = axes[1,0].plot(oneDPS[0], oneDPS[3], label='FGPA', alpha=0.5)\n",
    "axes[1,0].set_xlabel(r'$k\\ (\\mathrm{s/km})$', fontsize=14)\n",
    "axes[1,0].set_ylabel(r'$kP_\\mathrm{1D}/\\pi$', fontsize=14)\n",
    "axes[1,0].set_xscale('log')\n",
    "axes[1,0].set_yscale('log')\n",
    "axes[1,0].set_ylim(axes[1,0].get_ylim())\n",
    "axes[1,0].vlines(x=0.1, ymin=1e-8, ymax=1e8)\n",
    "axes[1,0].set_title('Average 1DPS', fontsize=14)\n",
    "axes[1,0].tick_params(labelsize=12, direction='in', which='both')\n",
    "customs = [p3,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p7,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p4]\n",
    "axes[1,0].legend(customs, [p3.get_label(), '$m=%.3f$'%accuracy_gen, '$s=%.3f$'%rela_err_gen, \n",
    "                    p7.get_label(),'$m=%.3f$'%accuracy_FGPA, '$s=%.3f$'%rela_err_FGPA,\n",
    "                    p4.get_label()], fontsize=12)\n",
    "\n",
    "p5, = axes[1,1].step(F_hist, outp_hist, where='post', label='Predicted')\n",
    "p6, = axes[1,1].step(F_hist, test_hist, where='post', label='Real', alpha=0.5)\n",
    "p8, = axes[1,1].step(F_hist, FGPA_hist, where='post', label='FGPA', alpha=0.5)\n",
    "axes[1,1].set_xlabel(r'$F$', fontsize=18)\n",
    "axes[1,1].set_ylabel(r'Counts', fontsize=18)\n",
    "axes[1,1].set_xlim([0, 1])\n",
    "axes[1,1].set_ylim(bottom=0)\n",
    "axes[1,1].vlines(x=0.1, ymin=0, ymax=6000)\n",
    "axes[1,1].vlines(x=0.9, ymin=0, ymax=6000)\n",
    "axes[1,1].set_title('Average PDF of $F$', fontsize=14)\n",
    "axes[1,1].tick_params(labelsize=12, direction='in')\n",
    "customs = [p5,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p8,\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          Line2D([0], [0], marker='o', color='w',\n",
    "                      markerfacecolor='k', markersize=5),\n",
    "          p6]\n",
    "axes[1,1].legend(customs, [p5.get_label(), '$m=%.3f$'%accuracy_hist, '$s=%.3f$'%rela_err_hist,\n",
    "                    p8.get_label(),'$m=%.3f$'%m_hist_FGPA, '$s=%.3f$'%s_hist_FGPA,\n",
    "                    p6.get_label()], fontsize=12)\n",
    "\n",
    "#plt.savefig(folder_outp / ('average.png'), dpi=300, bbox_inches='tight') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is unnormalized"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
